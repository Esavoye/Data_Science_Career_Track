{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capstone_1_In_Depth_Analysis",
      "provenance": [],
      "collapsed_sections": [
        "LLkK2eSTTR8e"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBCvmtGfo-Th",
        "colab_type": "text"
      },
      "source": [
        "# Springboard--DSC Program\n",
        "\n",
        "# Capstone Project 1 - In-Depth Analysis\n",
        "### by Ellen A. Savoye"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8excymRso7jd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "c35b3732-4614-497a-9a89-a7a7ba1901f7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9K1yheAu0A9",
        "colab_type": "text"
      },
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V69Mvr_uu9M9",
        "colab_type": "text"
      },
      "source": [
        "After creating new features during EDA and using statistical analysis to determine correlation between features, I continued on to build a pedictive model using that data.\n",
        "\n",
        "During EDA, I discovered my data was imbalanced where 92% of my data was labeled as non-toxic. Given the stark imbalance, I hypothesized my predictive model would be influenced by this.\n",
        "\n",
        "To test my hypothesis, I first built 2 baseline models: logisitic regression and Naive-Bayes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CyXoO9F6P983"
      },
      "source": [
        "# Import packages and data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9bv0hBza7DG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "505a7835-834f-479e-8e8c-cfefef21f83d"
      },
      "source": [
        "# !pip install wordcloud\n",
        "# !pip install kaggle\n",
        "# !pip install spacy\n",
        "# !pip install swifter\n",
        "# !pip install tqdm\n",
        "!pip install -U git+https://github.com/scikit-learn-contrib/imbalanced-learn.git"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/scikit-learn-contrib/imbalanced-learn.git\n",
            "  Cloning https://github.com/scikit-learn-contrib/imbalanced-learn.git to /tmp/pip-req-build-xevwdyz9\n",
            "  Running command git clone -q https://github.com/scikit-learn-contrib/imbalanced-learn.git /tmp/pip-req-build-xevwdyz9\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn==0.7.0) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn==0.7.0) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.23 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn==0.7.0) (0.23.1)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn==0.7.0) (0.15.1)\n",
            "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.23->imbalanced-learn==0.7.0) (2.1.0)\n",
            "Building wheels for collected packages: imbalanced-learn\n",
            "  Building wheel for imbalanced-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imbalanced-learn: filename=imbalanced_learn-0.7.0-cp36-none-any.whl size=167059 sha256=ad765bca225e8c0b10dd7068a994627521e0d7fc6cde0c2261139b527eed6024\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3hy6cfs4/wheels/6c/07/cf/38cb9b7cc9e6a0ac7648a80ec192b6f2d863405fb0049ac0ff\n",
            "Successfully built imbalanced-learn\n",
            "Installing collected packages: imbalanced-learn\n",
            "  Found existing installation: imbalanced-learn 0.7.0\n",
            "    Uninstalling imbalanced-learn-0.7.0:\n",
            "      Successfully uninstalled imbalanced-learn-0.7.0\n",
            "Successfully installed imbalanced-learn-0.7.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "imblearn"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V000gO_ZTLla",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "6e608f90-3da6-4467-cc95-03397a247837"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "from collections import Counter\n",
        "\n",
        "# libraries for NLP\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "import sklearn.model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_curve, roc_auc_score\n",
        "# ref: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report\n",
        "from six.moves import range\n",
        "import scipy.sparse\n",
        "\n",
        "# for imbalanced datasets\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "# libraries for getting and moving data\n",
        "import os\n",
        "from os import path\n",
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# for Images\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm8woaAUlSu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set seed\n",
        "np.random.seed(42)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E-nIhH492WG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "5f0afc45-83a9-4f01-9675-d0d08577fa91"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UStVLS0nbGO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# necessary dependencies for text pre-processing\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm', parse=True, tag=True, entity=True)\n",
        "#nlp_vec = spacy.load('en_vecs', parse = True, tag=True, #entity=True)\n",
        "tokenizer = ToktokTokenizer()\n",
        "stopword_list = nltk.corpus.stopwords.words('english')\n",
        "stopword_list.remove('no')\n",
        "stopword_list.remove('not')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg16C-vsbIAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set directories\n",
        "# Google Colab\n",
        "src = \"/content/drive/My Drive/DS-Capstone_1/Code/\"\n",
        "dst = \"/content/drive/My Drive/DS-Capstone_1/Data/\"\n",
        "\n",
        "# Local computer\n",
        "# src = \"C:\\\\Users\\\\ellen\\\\Documents\\\\GitHub\\\\Data_Science_Career_Track\\\\Capstone_1\\\\Code\\\\\"\n",
        "# dst = \"C:\\\\Users\\\\ellen\\\\Documents\\\\GitHub\\\\Data_Science_Career_Track\\\\Capstone_1\\\\Data\\\\\"\n",
        "\n",
        "# Work computer\n",
        "# src = \"C:\\\\Users\\\\esavoye\\\\Documents\\\\GitHub\\\\Data_Science_Career_Track\\\\Capstone_1\\\\Code\\\\\"\n",
        "# dst = \"C:\\\\Users\\\\esavoye\\\\Documents\\\\GitHub\\\\Data_Science_Career_Track\\\\Capstone_1\\\\Data\\\\\"\n",
        "\n",
        "# Computer path\n",
        "# unpickled_df = pd.read_pickle(dst + '/full_data_w_features.pkl')\n",
        "# unpickled_df_slimmed = pd.read_pickle(dst + '/slimmed_data_w_features.pkl')\n",
        "\n",
        "# Colab path\n",
        "unpickled_df = pd.read_pickle(dst + 'full_data_w_features.pkl')\n",
        "unpickled_df_slimmed = pd.read_pickle(dst + 'slimmed_data_w_features.pkl')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXC35_ykQd0X",
        "colab_type": "text"
      },
      "source": [
        "# Baseline Models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnKuf6C82ZKc",
        "colab_type": "text"
      },
      "source": [
        "Both logistic regression and naive bayes take an X and y input. After applying countvectorizer, the data is split into train and test sets. I'm using stratify to keep the split given that only 8% of the data is labelled as toxic. Without using stratify, the imbalance in my data has the potential to be even worse. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSWykPdfR4yJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# grab text field\n",
        "cleaned_text = unpickled_df.clean_text"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT91eWcoQm1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create an object of class - Count_Vectorizer\n",
        "vectorizer = CountVectorizer()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmKKr-ptSTsL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ce90ce3-40d0-4364-c863-d14659d7f3d9"
      },
      "source": [
        "# call `fit_transform` to build the vocabulary and to convert text to a bag of words\n",
        "x = vectorizer.fit_transform(cleaned_text)\n",
        "type(x)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse.csr.csr_matrix"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltz3ypR6SnUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inputs:\n",
        "#         critics: a Pandas dataframe that contains the dataset.\n",
        "#         In particular, this dataframe is expected to have a column \n",
        "#         called 'quote', and critics.quote is a Series containing\n",
        "#         all documents, which is this case are movie reviews.\n",
        "#\n",
        "#         vectorizer: is expected to be an object of a class from\n",
        "#         sklearn.feature_extraction.text, (*)\n",
        "#         or None, in which case, per the code below, is constructed\n",
        "#         according to class CountVectorizer.\n",
        "#\n",
        "# Outputs:\n",
        "#         X: document-term matrix associated with critics.quote,\n",
        "#         according to the vectorization implemented by object \n",
        "#         vectorizer.\n",
        "#\n",
        "#         y: this is the label vector, such that y[i] is the label\n",
        "#         associated with document i, encoded according to row i of X\n",
        "#\n",
        "#         vectorizer: vectorizer_object object built\n",
        "#**************************************************************************\n",
        "def make_xy(unpickled_df, vectorizer=None):\n",
        "    if vectorizer is None:\n",
        "        vectorizer = CountVectorizer()\n",
        "    X = vectorizer.fit_transform(unpickled_df.clean_text)\n",
        "    X = X.tocsc()\n",
        "    y = (unpickled_df.target_binary == 1).values.astype(np.int)\n",
        "    return X, y, vectorizer\n",
        "\n",
        "X, y, vectorizer = make_xy(unpickled_df)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G79aFHpXMUfW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Create file for use in the future \n",
        "# scipy.sparse.save_npz(dst + '/X.pkl', X)\n",
        "# np.save(dst + '/y.npy', y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41UnENsQNct1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load files for use in the future \n",
        "# X = scipy.sparse.load_npz(dst + 'X.pkl.npz')\n",
        "# y = np.load(dst + 'y.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTY8moUZaEuY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create x and y split for train and test sets \n",
        "\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, stratify=y)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sxYz6Iw-CFf",
        "colab_type": "text"
      },
      "source": [
        "After the data has been vectorized and split into training and test sets, we can move onto the first baseline model: logistic regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldG6qRMV2PvO",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIvRpZz161x_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "67d5af9b-4671-4957-e080-763c5f8b127d"
      },
      "source": [
        "# Construct the LogisticRegression model\n",
        "clf = LogisticRegression()\n",
        "\n",
        "# Fit the model on the trainng data.\n",
        "clf.fit(Xtrain, ytrain)\n",
        "\n",
        "# Print the accuracy from the testing data.\n",
        "y_predict_test = clf.predict(Xtest)\n",
        "print(\"\\n\")\n",
        "print(\"[Test] Accuracy score (y_predict_test, ytest):\",accuracy_score(y_predict_test, ytest))\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"[Test] Accuracy score: (ytest, y_predict_test)\",accuracy_score(ytest, y_predict_test))\n",
        "\n",
        "y_predict_training = clf.predict(Xtrain)\n",
        "print(\"\\n\")\n",
        "print(\"[Training] Accuracy score: (ytrain, y_predict_training)\",accuracy_score(ytrain, y_predict_training))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[Test] Accuracy score (y_predict_test, ytest): 0.9443684773912446\n",
            "\n",
            "\n",
            "[Test] Accuracy score: (ytest, y_predict_test) 0.9443684773912446\n",
            "\n",
            "\n",
            "[Training] Accuracy score: (ytrain, y_predict_training) 0.9464472114386605\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7RL3ksi-ilb",
        "colab_type": "text"
      },
      "source": [
        "When using accuracy to determine how 'good' a model is, one must keep in mind whether or not the data is balanced. Most datasets are not balanced and predictive models have a tendency to apply the dominant class across the board. The overall results show high accuracy given how large the dominant class is (92% of the data). To gauge the goodness of the model better, I put together a classification report on both the train and test sets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNdROyxqafLy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "87c4ee29-6a71-4cb0-958c-f1c98c53dd2e"
      },
      "source": [
        "# more comprehensive performance analysis\n",
        "\n",
        "target_names = ['Non-Toxic', 'Toxic']\n",
        "\n",
        "print(\"[Training Classification Report]\")\n",
        "print(classification_report(ytrain, y_predict_training, target_names=target_names))\n",
        "\n",
        "print(\"[Test Classification Report]\")\n",
        "print(classification_report(ytest, y_predict_test, target_names=target_names))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Training Classification Report]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Toxic       0.96      0.99      0.97   1245405\n",
            "       Toxic       0.76      0.48      0.59    108250\n",
            "\n",
            "    accuracy                           0.95   1353655\n",
            "   macro avg       0.86      0.74      0.78   1353655\n",
            "weighted avg       0.94      0.95      0.94   1353655\n",
            "\n",
            "[Test Classification Report]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Toxic       0.96      0.99      0.97    415135\n",
            "       Toxic       0.74      0.47      0.58     36084\n",
            "\n",
            "    accuracy                           0.94    451219\n",
            "   macro avg       0.85      0.73      0.77    451219\n",
            "weighted avg       0.94      0.94      0.94    451219\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EojCTwa_tuw",
        "colab_type": "text"
      },
      "source": [
        "There are 2 end goals: one is to determine a predictive model works best and two, test the hypothesis that the model is influenced by the imbalance. We already used stratification when creating the train/test split to mitigate some of the influence of the imbalance by not allowing it to become worse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqxZvpqnt51Y",
        "colab_type": "text"
      },
      "source": [
        "Since we can't simply say a model is excellent based on accuracy alone, as I explained previously, we need to take into consideration precision and recall. Precision will help us see how precise/accurate our model is by showing how many of the predicted positives (toxic/ True Positive) are actually positive. Recall will help us see how many of the actual positives our model truly captures through labeling it as a positive (toxic/ True Positive)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZ5C83xqCrm0",
        "colab_type": "text"
      },
      "source": [
        "Looking at the results of the logistic regression without hypertuning, we see that for the non-toxic label both precision and recall, ~0.96 and 0.99 respectively, are approximately the same between the train and test set. This means our model was accurate in identifying 99% of actual positives and mislabeling only 1%. Similarly, precision is ~96% showing that of the predicted positives, 4% were actually toxic. \n",
        "\n",
        "However, in predicting toxic comments, the model didn't do as well. The train set's precision is a 77% with a recall of 48%. Of the identified actual toxic comments, only 48% were accurately identified. The test set performed worse with a precision of 74% and a recall of 47%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Thn8zNmGFetR",
        "colab_type": "text"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vPXww8DBbT9",
        "colab_type": "text"
      },
      "source": [
        "Given the difference in accuracy between toxic and non-toxic for logistic regression, I'm going to see if using Naive Bayes as my predictive model gives me a more accurate model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdLLx4ujGEPb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f51f64f-b9b8-4429-d0ba-f04e080913fd"
      },
      "source": [
        "# multinomial naive bayes classifier\n",
        "nBayes = MultinomialNB()\n",
        "\n",
        "# same X and y used for logistic regression\n",
        "clf_nBayes = nBayes.fit(Xtrain, ytrain)\n",
        "\n",
        "accuracy_train = nBayes.score(Xtrain,ytrain)\n",
        "accuracy_test = nBayes.score(Xtest,ytest)\n",
        "\n",
        "print('The training accuracy is %f and the test accuracy is %f' %(accuracy_train, accuracy_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training accuracy is 0.929560 and the test accuracy is 0.916508\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KGAR8atI2T3",
        "colab_type": "text"
      },
      "source": [
        "The gap between training and test accuracy does not imply overfitting. However, we will still explore cross-validation and hyper-parameter fitting to generate the classification report and potentially a more accurate model.\n",
        "\n",
        "We only use the training data for hyper-parameter tuning. The test set is set aside and used to score the model at the end."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeAve-4fJcc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cross-Validation and hyper-parameter fitting\n",
        "\n",
        "def cv_score(clf, X, y, scorefunc):\n",
        "    result = 0.\n",
        "    nfold = 5\n",
        "    for train, test in KFold(nfold).split(X): # split data into train/test groups, 5 times\n",
        "        clf.fit(X[train], y[train]) # fit the classifier, passed is as clf.\n",
        "        result += scorefunc(clf, X[test], y[test]) # evaluate score function on held-out data\n",
        "    return result / nfold # average\n",
        "\n",
        "def log_likelihood(clf_nBayes, x, y):\n",
        "    prob = clf_nBayes.predict_log_proba(x)\n",
        "    toxic = y == 1\n",
        "    non_toxic = ~toxic\n",
        "    return prob[non_toxic, 0].sum() + prob[toxic, 1].sum()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7Md-hzdQSz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "itrain, itest = train_test_split(range(unpickled_df.shape[0]), train_size=0.7)\n",
        "mask=np.ones(unpickled_df.shape[0], dtype='int')\n",
        "mask[itrain]=1\n",
        "mask[itest]=0\n",
        "mask = (mask==1)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1pIFCVGRV4L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "outputId": "7567cbf6-2bb2-487a-af5e-52a121d1aa00"
      },
      "source": [
        "#the grid of parameters to search over\n",
        "alphas = [0, .1, 1, 5, 10, 50]\n",
        "min_dfs = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
        "\n",
        "#Find the best value for alpha and min_df, and the best classifier\n",
        "best_alpha = None\n",
        "best_min_df = None\n",
        "maxscore=-np.inf\n",
        "for alpha in alphas:\n",
        "    for min_df in min_dfs:         \n",
        "        vectorizer = CountVectorizer(min_df = min_df)       \n",
        "        Xthis, ythis, vectorizer = make_xy(unpickled_df)\n",
        "        Xtrainthis=Xthis[mask]\n",
        "        ytrainthis=ythis[mask]\n",
        "\n",
        "        clf_nBayes = MultinomialNB(alpha=alpha)\n",
        "        cvscore = cv_score(clf_nBayes, Xtrainthis, ytrainthis, log_likelihood)\n",
        "\n",
        "        if cvscore > maxscore:\n",
        "            maxscore = cvscore\n",
        "            best_alpha, best_min_df = alpha, min_df"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK9RQp14R2nF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "ddf50b28-3250-434e-d9d0-0a2daebabd34"
      },
      "source": [
        "print(\"alpha: %f\" % best_alpha)\n",
        "print(\"min_df: %f\" % best_min_df)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alpha: 1.000000\n",
            "min_df: 0.000010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewj5faJB-pcq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6fe26c31-4ba7-4a06-a13f-e23960a7af48"
      },
      "source": [
        "best_alpha = 1.000000\n",
        "best_min_df = 0.000010\n",
        "\n",
        "vectorizer = CountVectorizer(min_df=best_min_df)\n",
        "# X, y, vectorizer = make_xy(unpickled_df, vectorizer)\n",
        "xtrain=X[mask]\n",
        "ytrain=y[mask]\n",
        "xtest=X[~mask]\n",
        "ytest=y[~mask]\n",
        "\n",
        "clf = MultinomialNB(alpha=best_alpha).fit(xtrain, ytrain)\n",
        "\n",
        "# Print the accuracy on the test and training dataset\n",
        "training_accuracy = clf.score(xtrain, ytrain)\n",
        "test_accuracy = clf.score(xtest, ytest)\n",
        "\n",
        "print(\"Accuracy on training data: {:2f}\".format(training_accuracy))\n",
        "print(\"Accuracy on test data:     {:2f}\".format(test_accuracy))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training data: 0.889943\n",
            "Accuracy on test data:     0.885737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZpXCsAqc_RVd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "f8bcd899-ac82-465c-c044-9c370b0588ab"
      },
      "source": [
        "# Fit the model on the trainng data for NB\n",
        "clf.fit(xtrain, ytrain)\n",
        "\n",
        "# Print the accuracy from the testing data.\n",
        "y_predict_test = clf.predict(xtest)\n",
        "print(\"\\n\")\n",
        "print(\"[Test] Accuracy score (y_predict_test, ytest):\",accuracy_score(y_predict_test, ytest))\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"[Test] Accuracy score: (ytest, y_predict_test)\",accuracy_score(ytest, y_predict_test))\n",
        "\n",
        "y_predict_training = clf.predict(xtrain)\n",
        "print(\"\\n\")\n",
        "print(\"[Training] Accuracy score: (ytrain, y_predict_training)\",accuracy_score(ytrain, y_predict_training))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[Test] Accuracy score (y_predict_test, ytest): 0.8857373449340029\n",
            "\n",
            "\n",
            "[Test] Accuracy score: (ytest, y_predict_test) 0.8857373449340029\n",
            "\n",
            "\n",
            "[Training] Accuracy score: (ytrain, y_predict_training) 0.8899431776357812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CadboD-f_RVs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "a2a5102f-a79c-44c5-d477-589d1b39a7d1"
      },
      "source": [
        "# more comprehensive performance analysis for NB\n",
        "\n",
        "target_names = ['Non-Toxic', 'Toxic']\n",
        "\n",
        "print(\"[Training Classification Report]\")\n",
        "print(classification_report(ytrain, y_predict_training, target_names=target_names))\n",
        "\n",
        "print(\"[Test Classification Report]\")\n",
        "print(classification_report(ytest, y_predict_test, target_names=target_names))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Training Classification Report]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Toxic       0.97      0.91      0.94   1162221\n",
            "       Toxic       0.39      0.68      0.50    101190\n",
            "\n",
            "    accuracy                           0.89   1263411\n",
            "   macro avg       0.68      0.79      0.72   1263411\n",
            "weighted avg       0.92      0.89      0.90   1263411\n",
            "\n",
            "[Test Classification Report]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Toxic       0.97      0.91      0.94    498319\n",
            "       Toxic       0.37      0.65      0.47     43144\n",
            "\n",
            "    accuracy                           0.89    541463\n",
            "   macro avg       0.67      0.78      0.70    541463\n",
            "weighted avg       0.92      0.89      0.90    541463\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g2Ruc9OcATq4"
      },
      "source": [
        "Looking at the results of the hypertuned Naive Bayes, we see that for non-toxic both precision and recall, 0.97 and 0.91 respectively, are approximately the same between the train and test set. This means our model was accurate in identifying 97% of actual positives and mislabeling only 3%. Similarly, precision is 91% showing that of the predicted positives, 9% were actually toxic. \n",
        "\n",
        "However, in predicting toxic comments, the model didn't do as well which is similar to the results of the logistic regression. For Naive Bayes, the trade off is flipped from the logistic regression. The train set's precision is a 39% with a recall of 68%. The train set mislabeled over 50% of the data it said was toxic. Of the identified actual toxic comments, Naive Bayes identified 65% versus 48% for logisitic regression. The test set performed worse with a precision of 37% and a recall of 65%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPbX6lOhsDe0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate roc curve\n",
        "fpr, tpr, thresholds = roc_curve(ytrain, y_predict_training)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhuLwITDxOnm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d1a61b1d-25e3-4b84-84a6-53525cc29dfd"
      },
      "source": [
        "# calculate AUC\n",
        "auc = roc_auc_score(ytrain, y_predict_training)\n",
        "print('AUC: %.3f' % auc)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.793\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ-gjBr-rddc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "4bb00b69-6ab3-4b45-f560-1d3a9a163c2d"
      },
      "source": [
        "# plot the roc curve for the model\n",
        "plt.plot(fpr, tpr, linestyle='--')\n",
        "\n",
        "# axis labels\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "plt.legend()\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ38hW3pvheQ",
        "colab_type": "text"
      },
      "source": [
        "A good measure of separability implying an excellent model is an AUC near 1. When AUC is 0.5, it means model has no class separation capacity whatsoever. Given an AUC of ~0.8, it means there is 80% chance that model will be able to distinguish between positive class (toxic) and negative class (non-toxic).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q48KpfPgEYR7",
        "colab_type": "text"
      },
      "source": [
        "## Next Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wN0LpBT0Avhm",
        "colab_type": "text"
      },
      "source": [
        "Interestingly enough, the logisitic regression has poor recall while the naive bayes has poor precision. The logisitic regression classifier has an f1-score of .59 for toxic compared to the .5 f1-score of naive bayes. As such, I'm going to focus on improving recall using the Synthetic Minority Oversampling Technique (SMOTE) on the training set. In doing so, I'll be able to oversample my toxic label to, hopefully, train it better thus enabling a more accurate classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_qNuwUixSxY",
        "colab_type": "text"
      },
      "source": [
        "# SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi6tKqYBLabP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6adde501-b8b2-40ca-dc5e-43b327b09d1e"
      },
      "source": [
        "counter = Counter(ytrain)\n",
        "print(counter)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({0: 1245405, 1: 108250})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdMDlFKLkDDC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# oversample = SMOTE() with undersampling on the TRAINING SET ONLY\n",
        "over = SMOTE(sampling_strategy=0.2)\n",
        "under = RandomUnderSampler(sampling_strategy=0.5)\n",
        "steps = [('o', over), ('u', under)]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "# transform the dataset\n",
        "X_train_resample, y_train_resample = pipeline.fit_resample(Xtrain, ytrain)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AwQKYZDkXVS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "732e6acb-f5f1-41d8-dd7a-7ba56a2a4878"
      },
      "source": [
        "# summarize the new class distribution\n",
        "counter = Counter(y_train_resample)\n",
        "print(counter)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({0: 498162, 1: 249081})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFzx5XDFTYKz",
        "colab_type": "text"
      },
      "source": [
        "The original y training set had a split of non-toxic: 1,245,405 and toxic: 108,250. Comparatively, the new SMOTE y training set has a split of non-toxic: 498,162 and toxic: 249,081. The split went from 8% toxic to 33% toxic."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LLkK2eSTTR8e"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ijcE7tDxTR8g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "8cc67640-b8e3-427b-f65c-8dd374ed97e3"
      },
      "source": [
        "# Construct the LogisticRegression model\n",
        "clf = LogisticRegression()\n",
        "\n",
        "# Fit the model on the trainng data.\n",
        "clf.fit(X_train_resample, y_train_resample)\n",
        "\n",
        "# Print the accuracy from the testing data.\n",
        "y_predict_test = clf.predict(Xtest)\n",
        "print(\"\\n\")\n",
        "print(\"[Test] Accuracy score (y_predict_test, ytest):\",accuracy_score(y_predict_test, ytest))\n",
        "\n",
        "y_predict_training = clf.predict(X_train_resample)\n",
        "print(\"\\n\")\n",
        "print(\"[Training] Accuracy score: (ytrain, y_predict_training)\",accuracy_score(y_train_resample, y_predict_training))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[Test] Accuracy score (y_predict_test, ytest): 0.9215680190772109\n",
            "\n",
            "\n",
            "[Training] Accuracy score: (ytrain, y_predict_training) 0.8793297494924677\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zLPGizGtTR8l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "d485dbc0-cc07-464b-8a9e-6fd923db77dc"
      },
      "source": [
        "# more comprehensive performance analysis\n",
        "\n",
        "target_names = ['Non-Toxic', 'Toxic']\n",
        "\n",
        "print(\"[Training Classification Report]\")\n",
        "print(classification_report(y_train_resample, y_predict_training, target_names=target_names))\n",
        "\n",
        "print(\"[Test Classification Report]\")\n",
        "print(classification_report(ytest, y_predict_test, target_names=target_names))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Training Classification Report]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Toxic       0.88      0.95      0.91    498162\n",
            "       Toxic       0.87      0.74      0.80    249081\n",
            "\n",
            "    accuracy                           0.88    747243\n",
            "   macro avg       0.88      0.85      0.86    747243\n",
            "weighted avg       0.88      0.88      0.88    747243\n",
            "\n",
            "[Test Classification Report]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Toxic       0.97      0.94      0.96    415135\n",
            "       Toxic       0.51      0.69      0.58     36084\n",
            "\n",
            "    accuracy                           0.92    451219\n",
            "   macro avg       0.74      0.81      0.77    451219\n",
            "weighted avg       0.93      0.92      0.93    451219\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA9WN5xQWAx6",
        "colab_type": "text"
      },
      "source": [
        " Via SMOTE, my goal was to improve the recall of my classifier. I ran my original test set through the updated logistic regression classifier and created a new classification report. In comparison to my training baseline, precision increased from 0.76 to 0.87 and recall increased from 0.48 to 0.74 with an f1-score of 0.8. On my test dataset, precision decreased from 0.74 to 0.51. Recall increased from 0.47 to 0.69. My f1-score stayed the same at 0.58.\n",
        "\n",
        " Typically, as precision increases, recall decreases and vice versa which we can see on our test dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QGw8ahFbTR8o"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "st2osI3JTR8p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3f1bfc18-7f5a-4847-a1be-27b323e68a31"
      },
      "source": [
        "best_alpha = 1.000000\n",
        "best_min_df = 0.000010\n",
        "\n",
        "# multinomial naive bayes classifier\n",
        "nBayes = MultinomialNB(alpha=best_alpha)\n",
        "\n",
        "# same X and y used for logistic regression\n",
        "clf_nBayes = nBayes.fit(X_train_resample, y_train_resample)\n",
        "\n",
        "accuracy_train = nBayes.score(X_train_resample,y_train_resample)\n",
        "accuracy_test = nBayes.score(Xtest,ytest)\n",
        "\n",
        "print('The training accuracy is %f and the test accuracy is %f' %(accuracy_train, accuracy_test))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training accuracy is 0.809620 and the test accuracy is 0.816393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bYSgH7Z9TR8s"
      },
      "source": [
        "The gap between training and test accuracy does not imply overfitting. However, one interesting point is the training accuracy decreased from 0.929560 and the test accuracy decreased from 0.916508."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "e--Q-OabTR8t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "b89fe2bb-4a1d-49af-d49c-1fa9cded1e4b"
      },
      "source": [
        "\n",
        "# Print the accuracy from the testing data.\n",
        "y_predict_test = clf_nBayes.predict(Xtest)\n",
        "print(\"\\n\")\n",
        "print(\"[Test] Accuracy score (y_predict_test, ytest):\",accuracy_score(y_predict_test, ytest))\n",
        "\n",
        "y_predict_training = clf_nBayes.predict(X_train_resample)\n",
        "print(\"\\n\")\n",
        "print(\"[Training] Accuracy score: (ytrain, y_predict_training)\",accuracy_score(y_train_resample, y_predict_training))\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[Test] Accuracy score (y_predict_test, ytest): 0.8163929267162952\n",
            "\n",
            "\n",
            "[Training] Accuracy score: (ytrain, y_predict_training) 0.8096201637218415\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sqifrG9GTR8w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "c262fede-077a-4cee-f366-1a46ffa2c9e9"
      },
      "source": [
        "# more comprehensive performance analysis for NB\n",
        "\n",
        "target_names = ['Non-Toxic', 'Toxic']\n",
        "\n",
        "print(\"[Training Classification Report]\")\n",
        "print(classification_report(y_train_resample, y_predict_training, target_names=target_names))\n",
        "\n",
        "print(\"[Test Classification Report]\")\n",
        "print(classification_report(ytest, y_predict_test, target_names=target_names))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Training Classification Report]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Toxic       0.88      0.83      0.85    498162\n",
            "       Toxic       0.69      0.78      0.73    249081\n",
            "\n",
            "    accuracy                           0.81    747243\n",
            "   macro avg       0.79      0.80      0.79    747243\n",
            "weighted avg       0.82      0.81      0.81    747243\n",
            "\n",
            "[Test Classification Report]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Toxic       0.98      0.82      0.89    415135\n",
            "       Toxic       0.27      0.76      0.40     36084\n",
            "\n",
            "    accuracy                           0.82    451219\n",
            "   macro avg       0.62      0.79      0.65    451219\n",
            "weighted avg       0.92      0.82      0.85    451219\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_LtUN6DsTR8y"
      },
      "source": [
        "Opposite to the logistic regression results, the non-toxic and toxic classification for both the train and test set decreased in precision, recall, and f1-score across the board. Applying SMOTE to my Naive-Bayes classifier made my model worse."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "U9E6lnboTR8z",
        "colab": {}
      },
      "source": [
        "# calculate roc curve\n",
        "fpr, tpr, thresholds = roc_curve(y_train_resample, y_predict_training)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ulwBs0clTR81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d1d695c-4876-4041-8474-d1d1d8f83891"
      },
      "source": [
        "# calculate AUC\n",
        "auc = roc_auc_score(y_train_resample, y_predict_training)\n",
        "print('AUC: %.3f' % auc)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.801\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "78QRyrfWTR83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "ffc1ea48-6144-4a49-98f8-f27c8d2cbf25"
      },
      "source": [
        "# plot the roc curve for the model\n",
        "plt.plot(fpr, tpr, linestyle='--')\n",
        "\n",
        "# axis labels\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "plt.legend()\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LAAlrVrTTR85"
      },
      "source": [
        "The baseline and SMOTE AUC are both 0.8 so applying SMOTE did not change. The implication being the model's ability to distinguish between positive class (toxic) and negative class (non-toxic) did improve.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSa0Z61ypbmU",
        "colab_type": "text"
      },
      "source": [
        "# Wrap-Up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptCVjAUMpeKM",
        "colab_type": "text"
      },
      "source": [
        "My hypothesis was that I believed my baseline classifier would be influenced by the imbalance that exists within my original dataset. In my baseline classifiers, there is a distinct difference between both classifiers' ability to identity the toxic label which supports my hypothesis. After applying SMOTE, my logistic regression classifier became more accurate in correctly classifying the toxic label. Not only did my recall increase on my test set but both precision and recall increased on my training set. \n",
        "\n",
        "In comparison, the naive bayes classifier did not fare well post-SMOTE. My classifier became less accurate.\n",
        "\n",
        "Based on the outcome of my baseline classifiers, I believe my baseline classifiers were influenced by the inherent imbalance within the data. In choosing a classifier, after my testing, I would choose the logistic regression classifier."
      ]
    }
  ]
}