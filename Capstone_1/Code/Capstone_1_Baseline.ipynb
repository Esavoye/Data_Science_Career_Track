{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capstone_1_Baseline",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBCvmtGfo-Th",
        "colab_type": "text"
      },
      "source": [
        "# Springboard--DSC Program\n",
        "\n",
        "# Capstone Project 1 - Regression\n",
        "### by Ellen A. Savoye"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8excymRso7jd",
        "colab_type": "code",
        "outputId": "dbbf7b0a-4ad4-4ce9-ed1b-432591d22fe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CyXoO9F6P983"
      },
      "source": [
        "# Import packages and data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9bv0hBza7DG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install wordcloud\n",
        "# !pip install kaggle\n",
        "# !pip install spacy\n",
        "# !pip install swifter\n",
        "# !pip install tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V000gO_ZTLla",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "ff3bc832-eadb-4612-a441-27066ca0d95c"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "from collections import Counter\n",
        "\n",
        "# libraries for NLP\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "import sklearn.model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "# ref: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report\n",
        "from six.moves import range\n",
        "\n",
        "# libraries for getting and moving data\n",
        "import os\n",
        "from os import path\n",
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# for Images\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_wKFpFJbDNl",
        "colab_type": "code",
        "outputId": "ad04c396-77d5-435c-ed4c-09de036fc31f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# google colab only\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UStVLS0nbGO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# necessary dependencies for text pre-processing\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm', parse=True, tag=True, entity=True)\n",
        "#nlp_vec = spacy.load('en_vecs', parse = True, tag=True, #entity=True)\n",
        "tokenizer = ToktokTokenizer()\n",
        "stopword_list = nltk.corpus.stopwords.words('english')\n",
        "stopword_list.remove('no')\n",
        "stopword_list.remove('not')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg16C-vsbIAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set directories\n",
        "# Google Colab\n",
        "src = \"/content/drive/My Drive/DS-Capstone_1/Code/\"\n",
        "dst = \"/content/drive/My Drive/DS-Capstone_1/Data/\"\n",
        "\n",
        "# Local computer\n",
        "# src = \"C:\\\\Users\\\\ellen\\\\Documents\\\\GitHub\\\\Data_Science_Career_Track\\\\Capstone_1\\\\Code\\\\\"\n",
        "# dst = \"C:\\\\Users\\\\ellen\\\\Documents\\\\GitHub\\\\Data_Science_Career_Track\\\\Capstone_1\\\\Data\\\\\"\n",
        "\n",
        "# Work computer\n",
        "# src = \"C:\\\\Users\\\\esavoye\\\\Documents\\\\GitHub\\\\Data_Science_Career_Track\\\\Capstone_1\\\\Code\\\\\"\n",
        "# dst = \"C:\\\\Users\\\\esavoye\\\\Documents\\\\GitHub\\\\Data_Science_Career_Track\\\\Capstone_1\\\\Data\\\\\"\n",
        "\n",
        "# Computer path\n",
        "# unpickled_df = pd.read_pickle(dst + '/full_data_w_features.pkl')\n",
        "# unpickled_df_slimmed = pd.read_pickle(dst + '/slimmed_data_w_features.pkl')\n",
        "\n",
        "# Colab path\n",
        "unpickled_df = pd.read_pickle(dst + 'full_data_w_features.pkl')\n",
        "unpickled_df_slimmed = pd.read_pickle(dst + 'slimmed_data_w_features.pkl')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXC35_ykQd0X",
        "colab_type": "text"
      },
      "source": [
        "# Test Set & Countvectorizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnKuf6C82ZKc",
        "colab_type": "text"
      },
      "source": [
        "Both logistic regression and naive bayes take an X and y input. After applying countvectorizer, the data is split into train and test sets. I'm using stratify to keep the split given that only 8% of the data is labelled as toxic. Without using stratify, the imbalance in my data has the potential to be even worse. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSWykPdfR4yJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# grab text field\n",
        "cleaned_text = unpickled_df.clean_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT91eWcoQm1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create an object of class - Count_Vectorizer\n",
        "vectorizer = CountVectorizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmKKr-ptSTsL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "931588a9-6f40-4b36-a3b2-dd237e852e16"
      },
      "source": [
        "# call `fit_transform` to build the vocabulary and to convert text to a bag of words\n",
        "x = vectorizer.fit_transform(cleaned_text)\n",
        "type(x)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse.csr.csr_matrix"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltz3ypR6SnUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inputs:\n",
        "#         critics: a Pandas dataframe that contains the dataset.\n",
        "#         In particular, this dataframe is expected to have a column \n",
        "#         called 'quote', and critics.quote is a Series containing\n",
        "#         all documents, which is this case are movie reviews.\n",
        "#\n",
        "#         vectorizer: is expected to be an object of a class from\n",
        "#         sklearn.feature_extraction.text, (*)\n",
        "#         or None, in which case, per the code below, is constructed\n",
        "#         according to class CountVectorizer.\n",
        "#\n",
        "# Outputs:\n",
        "#         X: document-term matrix associated with critics.quote,\n",
        "#         according to the vectorization implemented by object \n",
        "#         vectorizer.\n",
        "#\n",
        "#         y: this is the label vector, such that y[i] is the label\n",
        "#         associated with document i, encoded according to row i of X\n",
        "#\n",
        "#         vectorizer: vectorizer_object object built\n",
        "#**************************************************************************\n",
        "def make_xy(unpickled_df, vectorizer=None):\n",
        "    if vectorizer is None:\n",
        "        vectorizer = CountVectorizer()\n",
        "    X = vectorizer.fit_transform(unpickled_df.clean_text)\n",
        "    X = X.tocsc()\n",
        "    y = (unpickled_df.target_binary == 1).values.astype(np.int)\n",
        "    return X, y, vectorizer\n",
        "\n",
        "X, y, vectorizer = make_xy(unpickled_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTY8moUZaEuY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create x and y split for train and test sets \n",
        "\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, stratify=y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldG6qRMV2PvO",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIvRpZz161x_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "95fe7932-e398-4033-b704-33becc75d887"
      },
      "source": [
        "# Construct the LogisticRegression model\n",
        "clf = LogisticRegression()\n",
        "\n",
        "# Fit the model on the trainng data.\n",
        "clf.fit(Xtrain, ytrain)\n",
        "\n",
        "# Print the accuracy from the testing data.\n",
        "y_predict_test = clf.predict(Xtest)\n",
        "print(\"\\n\")\n",
        "print(\"[Test] Accuracy score (y_predict_test, ytest):\",accuracy_score(y_predict_test, ytest))\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"[Test] Accuracy score: (ytest, y_predict_test)\",accuracy_score(ytest, y_predict_test))\n",
        "\n",
        "y_predict_training = clf.predict(Xtrain)\n",
        "print(\"\\n\")\n",
        "print(\"[Training] Accuracy score: (ytrain, y_predict_training)\",accuracy_score(ytrain, y_predict_training))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[Test] Accuracy score (y_predict_test, ytest): 0.9442332880485973\n",
            "\n",
            "\n",
            "[Test] Accuracy score: (ytest, y_predict_test) 0.9442332880485973\n",
            "\n",
            "\n",
            "[Training] Accuracy score: (ytrain, y_predict_training) 0.9475582774045085\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNdROyxqafLy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "8f3ae76f-400f-4e05-b596-4242d148439a"
      },
      "source": [
        "# more comprehensive performance analysis\n",
        "\n",
        "target_names = ['Non-Toxic', 'Toxic']\n",
        "\n",
        "print(\"[Training Classification Report]\")\n",
        "print(classification_report(ytrain, y_predict_training, target_names=target_names))\n",
        "\n",
        "print(\"[Test Classification Report]\")\n",
        "print(classification_report(ytest, y_predict_test, target_names=target_names))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Training Classification Report]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Toxic       0.96      0.99      0.97   1245405\n",
            "       Toxic       0.77      0.49      0.60    108250\n",
            "\n",
            "    accuracy                           0.95   1353655\n",
            "   macro avg       0.86      0.74      0.79   1353655\n",
            "weighted avg       0.94      0.95      0.94   1353655\n",
            "\n",
            "[Test Classification Report]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Toxic       0.96      0.99      0.97    415135\n",
            "       Toxic       0.74      0.47      0.58     36084\n",
            "\n",
            "    accuracy                           0.94    451219\n",
            "   macro avg       0.85      0.73      0.77    451219\n",
            "weighted avg       0.94      0.94      0.94    451219\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqxZvpqnt51Y",
        "colab_type": "text"
      },
      "source": [
        "The end goal is to determine which model would be the best for identifying non-toxic and toxic comments. Given how imbalanced the data is, we can't simply say a model is excellent based on accuracy alone. If you were to pick a random comment in the data, chances are high that it would be non-toxic given that 92% of the data is labeled non-toxic.\n",
        "\n",
        "As such, we need to take into consideration precision and recall. Precision will help us see how precise/accurate our model by showing how many of the predicted positives (toxic/ True Positive) are actually positive. Recall will help us see how many of the actual positives our model truly captures through labeling it as a positive (toxic/ True Positive)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZ5C83xqCrm0",
        "colab_type": "text"
      },
      "source": [
        "Looking at the results of the logistic regression without hypertuning, we see that for non-toxic both precision and recall, ~0.94 and 0.98 respectively, are approximately the same between the train and test set. This means our model was accurate in identifying 98% of actual positives and mislabeling only 2%. Similarly, precision is ~94% showing that of the predicted positives, 6% were actually toxic. \n",
        "\n",
        "However, in predicting toxic comments, the model didn't do as well. The train set's precision is a 78% with a recall of 48%. Of the identified actual toxic comments, only 48% were accurately identified. The test set performed worse with a precision of 70% and a recall of 43%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Thn8zNmGFetR",
        "colab_type": "text"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdLLx4ujGEPb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1122cb2c-a71c-4147-9cf0-0443b8dcb835"
      },
      "source": [
        "# multinomial naive bayes classifier\n",
        "nBayes = MultinomialNB()\n",
        "\n",
        "# same X and y used for logistic regression\n",
        "clf_nBayes = nBayes.fit(Xtrain, ytrain)\n",
        "\n",
        "accuracy_train = nBayes.score(Xtrain,ytrain)\n",
        "accuracy_test = nBayes.score(Xtest,ytest)\n",
        "\n",
        "print('The training accuracy is %f and the test accuracy is %f' %(accuracy_train, accuracy_test))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training accuracy is 0.929749 and the test accuracy is 0.915894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KGAR8atI2T3",
        "colab_type": "text"
      },
      "source": [
        "The gap between training and test accuracy does not imply overfitting. However, we still explore cross-validation and hyper-parameter fitting to generate the classification report and potentially a more accurate model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeAve-4fJcc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cross-Validation and hyper-parameter fitting\n",
        "\n",
        "def cv_score(clf, X, y, scorefunc):\n",
        "    result = 0.\n",
        "    nfold = 5\n",
        "    for train, test in KFold(nfold).split(X): # split data into train/test groups, 5 times\n",
        "        clf.fit(X[train], y[train]) # fit the classifier, passed is as clf.\n",
        "        result += scorefunc(clf, X[test], y[test]) # evaluate score function on held-out data\n",
        "    return result / nfold # average\n",
        "\n",
        "def log_likelihood(clf_nBayes, x, y):\n",
        "    prob = clf_nBayes.predict_log_proba(x)\n",
        "    toxic = y == 1\n",
        "    non_toxic = ~toxic\n",
        "    return prob[non_toxic, 0].sum() + prob[toxic, 1].sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7Md-hzdQSz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "itrain, itest = train_test_split(range(unpickled_df.shape[0]), train_size=0.7)\n",
        "mask=np.ones(unpickled_df.shape[0], dtype='int')\n",
        "mask[itrain]=0\n",
        "mask[itest]=1\n",
        "mask = (mask==1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1pIFCVGRV4L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "outputId": "1799b4da-3716-406f-cd40-99f5ac4083d5"
      },
      "source": [
        "#the grid of parameters to search over\n",
        "alphas = [0, .1, 1, 5, 10, 50]\n",
        "min_dfs = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
        "\n",
        "#Find the best value for alpha and min_df, and the best classifier\n",
        "best_alpha = None\n",
        "best_min_df = None\n",
        "maxscore=-np.inf\n",
        "for alpha in alphas:\n",
        "    for min_df in min_dfs:         \n",
        "        vectorizer = CountVectorizer(min_df = min_df)       \n",
        "        Xthis, ythis, vectorizer = make_xy(unpickled_df)\n",
        "        Xtrainthis=Xthis[mask]\n",
        "        ytrainthis=ythis[mask]\n",
        "\n",
        "        clf_nBayes = MultinomialNB(alpha=alpha)\n",
        "        cvscore = cv_score(clf_nBayes, Xtrainthis, ytrainthis, log_likelihood)\n",
        "\n",
        "        if cvscore > maxscore:\n",
        "            maxscore = cvscore\n",
        "            best_alpha, best_min_df = alpha, min_df"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK9RQp14R2nF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "f192e697-2c43-4ea5-8757-f3c6a47ea693"
      },
      "source": [
        "print(\"alpha: %f\" % best_alpha)\n",
        "print(\"min_df: %f\" % best_min_df)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alpha: 0.100000\n",
            "min_df: 0.000010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewj5faJB-pcq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a47232ce-7002-408c-ed4a-0087d689187e"
      },
      "source": [
        "best_alpha = 0.100000\n",
        "best_min_df = 0.000010\n",
        "\n",
        "vectorizer = CountVectorizer(min_df=best_min_df)\n",
        "X, y, vectorizer = make_xy(unpickled_df, vectorizer)\n",
        "xtrain=X[mask]\n",
        "ytrain=y[mask]\n",
        "xtest=X[~mask]\n",
        "ytest=y[~mask]\n",
        "\n",
        "clf = MultinomialNB(alpha=best_alpha).fit(xtrain, ytrain)\n",
        "\n",
        "# Print the accuracy on the test and training dataset\n",
        "training_accuracy = clf.score(xtrain, ytrain)\n",
        "test_accuracy = clf.score(xtest, ytest)\n",
        "\n",
        "print(\"Accuracy on training data: {:2f}\".format(training_accuracy))\n",
        "print(\"Accuracy on test data:     {:2f}\".format(test_accuracy))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training data: 0.898239\n",
            "Accuracy on test data:     0.888059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DnvWwS6k8Yz",
        "colab_type": "text"
      },
      "source": [
        "Recall - the ability of a model to find all the relevant cases within a dataset. Recall can be thought as of a model’s ability to find all the data points of interest in a dataset - correct results of the results that SHOULD HAVE been returned\n",
        "\n",
        "In the case of recall, when we increase the recall, we decrease the precision\n",
        "\n",
        "Precision - the ability of a classification model to identify only the relevant data points - correct results of results returned\n",
        "\n",
        "The F1 score is the harmonic mean of precision and recall. If we want to create a balanced classification model with the optimal balance of recall and precision, then we try to maximize the F1 score\n",
        "\n",
        "ROC curve?? quantify a model’s ROC curve by calculating the total Area Under the Curve (AUC), a metric which falls between 0 and 1 with a higher number indicating better classification performance. In the graph above, the AUC for the blue curve will be greater than that for the red curve, meaning the blue model is better at achieving a blend of precision and recall. A random classifier (the black line) achieves an AUC of 0.5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMS9Ab9hh9YL",
        "colab_type": "text"
      },
      "source": [
        "DID:\n",
        "vectorize -\n",
        "\n",
        "have matrix (X) and vector (y)\n",
        "\n",
        "logistic regression - fit(X, y)\n",
        "base model\n",
        "\n",
        "can apply any classification that has an X, y \n",
        "\n",
        "Naive Bayes & Logisitic Reg\n",
        "\n",
        "use more than accuracy\n",
        "classification report\n",
        "look at both training and classification/testing and classification\n",
        "\n",
        "DID:\n",
        "LOGISITIC REGRESSION\n",
        "first with regularization: if large gap then go onto 2nd\n",
        "  - 2nd with hypertuning L1/L2\n",
        "\n",
        "accuracy, precision, recall, F1\n",
        "train/test split\n",
        "- stratification (used to preserve split between toxic/non-toxic)\n",
        "\n",
        "\n",
        "what does it mean for the both classes in the underlying context of the business problem?\n",
        "explain recall and precision etc for context\n",
        "\n",
        "Make note of which method i used of the future question\n",
        "\n",
        "Future question \n",
        "\n",
        "1 - split first then vectorize\n",
        "or \n",
        "2 - vectorize then split\n",
        "\n",
        "\n",
        "what would that mean to do split then vectorize and what would it mean to a machine learning application?\n"
      ]
    }
  ]
}