{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capstone_1_Baseline",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBCvmtGfo-Th",
        "colab_type": "text"
      },
      "source": [
        "# Springboard--DSC Program\n",
        "\n",
        "# Capstone Project 1 - Regression\n",
        "### by Ellen A. Savoye"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8excymRso7jd",
        "colab_type": "code",
        "outputId": "f68e98b4-baac-44c6-e146-f90dc87f8de3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CyXoO9F6P983"
      },
      "source": [
        "# Import packages and data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9bv0hBza7DG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install wordcloud\n",
        "# !pip install kaggle\n",
        "# !pip install spacy\n",
        "# !pip install swifter\n",
        "# !pip install tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V000gO_ZTLla",
        "colab_type": "code",
        "outputId": "a8d1caa3-8644-44c5-c2ab-8531be9b6e12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "from collections import Counter\n",
        "\n",
        "# libraries for NLP\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "import sklearn.model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_curve, roc_auc_score\n",
        "# ref: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report\n",
        "from six.moves import range\n",
        "\n",
        "# libraries for getting and moving data\n",
        "import os\n",
        "from os import path\n",
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# for Images\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "%matplotlib inline"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_wKFpFJbDNl",
        "colab_type": "code",
        "outputId": "e0bcc8ab-e5c0-40c6-8108-253d3326351e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# google colab only\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UStVLS0nbGO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# necessary dependencies for text pre-processing\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm', parse=True, tag=True, entity=True)\n",
        "#nlp_vec = spacy.load('en_vecs', parse = True, tag=True, #entity=True)\n",
        "tokenizer = ToktokTokenizer()\n",
        "stopword_list = nltk.corpus.stopwords.words('english')\n",
        "stopword_list.remove('no')\n",
        "stopword_list.remove('not')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg16C-vsbIAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set directories\n",
        "# Google Colab\n",
        "src = \"/content/drive/My Drive/DS-Capstone_1/Code/\"\n",
        "dst = \"/content/drive/My Drive/DS-Capstone_1/Data/\"\n",
        "\n",
        "# Local computer\n",
        "# src = \"C:\\\\Users\\\\ellen\\\\Documents\\\\GitHub\\\\Data_Science_Career_Track\\\\Capstone_1\\\\Code\\\\\"\n",
        "# dst = \"C:\\\\Users\\\\ellen\\\\Documents\\\\GitHub\\\\Data_Science_Career_Track\\\\Capstone_1\\\\Data\\\\\"\n",
        "\n",
        "# Work computer\n",
        "# src = \"C:\\\\Users\\\\esavoye\\\\Documents\\\\GitHub\\\\Data_Science_Career_Track\\\\Capstone_1\\\\Code\\\\\"\n",
        "# dst = \"C:\\\\Users\\\\esavoye\\\\Documents\\\\GitHub\\\\Data_Science_Career_Track\\\\Capstone_1\\\\Data\\\\\"\n",
        "\n",
        "# Computer path\n",
        "# unpickled_df = pd.read_pickle(dst + '/full_data_w_features.pkl')\n",
        "# unpickled_df_slimmed = pd.read_pickle(dst + '/slimmed_data_w_features.pkl')\n",
        "\n",
        "# Colab path\n",
        "unpickled_df = pd.read_pickle(dst + 'full_data_w_features.pkl')\n",
        "unpickled_df_slimmed = pd.read_pickle(dst + 'slimmed_data_w_features.pkl')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXC35_ykQd0X",
        "colab_type": "text"
      },
      "source": [
        "# Test Set & Countvectorizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnKuf6C82ZKc",
        "colab_type": "text"
      },
      "source": [
        "Both logistic regression and naive bayes take an X and y input. After applying countvectorizer, the data is split into train and test sets. I'm using stratify to keep the split given that only 8% of the data is labelled as toxic. Without using stratify, the imbalance in my data has the potential to be even worse. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSWykPdfR4yJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# grab text field\n",
        "cleaned_text = unpickled_df.clean_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT91eWcoQm1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create an object of class - Count_Vectorizer\n",
        "vectorizer = CountVectorizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmKKr-ptSTsL",
        "colab_type": "code",
        "outputId": "784291c2-2aa2-424e-b5fa-51a7b3582837",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# call `fit_transform` to build the vocabulary and to convert text to a bag of words\n",
        "x = vectorizer.fit_transform(cleaned_text)\n",
        "type(x)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse.csr.csr_matrix"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltz3ypR6SnUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inputs:\n",
        "#         critics: a Pandas dataframe that contains the dataset.\n",
        "#         In particular, this dataframe is expected to have a column \n",
        "#         called 'quote', and critics.quote is a Series containing\n",
        "#         all documents, which is this case are movie reviews.\n",
        "#\n",
        "#         vectorizer: is expected to be an object of a class from\n",
        "#         sklearn.feature_extraction.text, (*)\n",
        "#         or None, in which case, per the code below, is constructed\n",
        "#         according to class CountVectorizer.\n",
        "#\n",
        "# Outputs:\n",
        "#         X: document-term matrix associated with critics.quote,\n",
        "#         according to the vectorization implemented by object \n",
        "#         vectorizer.\n",
        "#\n",
        "#         y: this is the label vector, such that y[i] is the label\n",
        "#         associated with document i, encoded according to row i of X\n",
        "#\n",
        "#         vectorizer: vectorizer_object object built\n",
        "#**************************************************************************\n",
        "def make_xy(unpickled_df, vectorizer=None):\n",
        "    if vectorizer is None:\n",
        "        vectorizer = CountVectorizer()\n",
        "    X = vectorizer.fit_transform(unpickled_df.clean_text)\n",
        "    X = X.tocsc()\n",
        "    y = (unpickled_df.target_binary == 1).values.astype(np.int)\n",
        "    return X, y, vectorizer\n",
        "\n",
        "X, y, vectorizer = make_xy(unpickled_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTY8moUZaEuY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create x and y split for train and test sets \n",
        "\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, stratify=y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaY_KFyIPN6f",
        "colab_type": "text"
      },
      "source": [
        "look at proportion of imbalance in train and test split\n",
        "run with 90/10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldG6qRMV2PvO",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIvRpZz161x_",
        "colab_type": "code",
        "outputId": "8077434f-1a04-4bde-c6c1-6e7a59a88eb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "# Construct the LogisticRegression model\n",
        "clf = LogisticRegression()\n",
        "\n",
        "# Fit the model on the trainng data.\n",
        "clf.fit(Xtrain, ytrain)\n",
        "\n",
        "# Print the accuracy from the testing data.\n",
        "y_predict_test = clf.predict(Xtest)\n",
        "print(\"\\n\")\n",
        "print(\"[Test] Accuracy score (y_predict_test, ytest):\",accuracy_score(y_predict_test, ytest))\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"[Test] Accuracy score: (ytest, y_predict_test)\",accuracy_score(ytest, y_predict_test))\n",
        "\n",
        "y_predict_training = clf.predict(Xtrain)\n",
        "print(\"\\n\")\n",
        "print(\"[Training] Accuracy score: (ytrain, y_predict_training)\",accuracy_score(ytrain, y_predict_training))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[Test] Accuracy score (y_predict_test, ytest): 0.9438964228013448\n",
            "\n",
            "\n",
            "[Test] Accuracy score: (ytest, y_predict_test) 0.9438964228013448\n",
            "\n",
            "\n",
            "[Training] Accuracy score: (ytrain, y_predict_training) 0.9465255179495514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNdROyxqafLy",
        "colab_type": "code",
        "outputId": "0b2d3eaf-019d-423b-ad11-8d76372b4624",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "# more comprehensive performance analysis\n",
        "\n",
        "target_names = ['Non-Toxic', 'Toxic']\n",
        "\n",
        "print(\"[Training Classification Report]\")\n",
        "print(classification_report(ytrain, y_predict_training, target_names=target_names))\n",
        "\n",
        "print(\"[Test Classification Report]\")\n",
        "print(classification_report(ytest, y_predict_test, target_names=target_names))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Training Classification Report]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Toxic       0.96      0.99      0.97   1245405\n",
            "       Toxic       0.76      0.49      0.59    108250\n",
            "\n",
            "    accuracy                           0.95   1353655\n",
            "   macro avg       0.86      0.74      0.78   1353655\n",
            "weighted avg       0.94      0.95      0.94   1353655\n",
            "\n",
            "[Test Classification Report]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Toxic       0.96      0.99      0.97    415135\n",
            "       Toxic       0.73      0.47      0.57     36084\n",
            "\n",
            "    accuracy                           0.94    451219\n",
            "   macro avg       0.84      0.73      0.77    451219\n",
            "weighted avg       0.94      0.94      0.94    451219\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqxZvpqnt51Y",
        "colab_type": "text"
      },
      "source": [
        "The end goal is to determine which model would be the best for identifying non-toxic and toxic comments. Given how imbalanced the data is, we can't simply say a model is excellent based on accuracy alone. If you were to pick a random comment in the data, chances are high that it would be non-toxic given that 92% of the data is labeled non-toxic.\n",
        "\n",
        "As such, we need to take into consideration precision and recall. Precision will help us see how precise/accurate our model by showing how many of the predicted positives (toxic/ True Positive) are actually positive. Recall will help us see how many of the actual positives our model truly captures through labeling it as a positive (toxic/ True Positive)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZ5C83xqCrm0",
        "colab_type": "text"
      },
      "source": [
        "Looking at the results of the logistic regression without hypertuning, we see that for non-toxic both precision and recall, ~0.96 and 0.99 respectively, are approximately the same between the train and test set. This means our model was accurate in identifying 99% of actual positives and mislabeling only 1%. Similarly, precision is ~96% showing that of the predicted positives, 4% were actually toxic. \n",
        "\n",
        "However, in predicting toxic comments, the model didn't do as well. The train set's precision is a 76% with a recall of 49%. Of the identified actual toxic comments, only 49% were accurately identified. The test set performed worse with a precision of 73% and a recall of 47%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Thn8zNmGFetR",
        "colab_type": "text"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdLLx4ujGEPb",
        "colab_type": "code",
        "outputId": "ec9e68b4-0db1-4e07-b381-24d56a474ce4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# multinomial naive bayes classifier\n",
        "nBayes = MultinomialNB()\n",
        "\n",
        "# same X and y used for logistic regression\n",
        "clf_nBayes = nBayes.fit(Xtrain, ytrain)\n",
        "\n",
        "accuracy_train = nBayes.score(Xtrain,ytrain)\n",
        "accuracy_test = nBayes.score(Xtest,ytest)\n",
        "\n",
        "print('The training accuracy is %f and the test accuracy is %f' %(accuracy_train, accuracy_test))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training accuracy is 0.929652 and the test accuracy is 0.916027\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KGAR8atI2T3",
        "colab_type": "text"
      },
      "source": [
        "The gap between training and test accuracy does not imply overfitting. However, we still explore cross-validation and hyper-parameter fitting to generate the classification report and potentially a more accurate model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeAve-4fJcc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Cross-Validation and hyper-parameter fitting\n",
        "\n",
        "def cv_score(clf, X, y, scorefunc):\n",
        "    result = 0.\n",
        "    nfold = 5\n",
        "    for train, test in KFold(nfold).split(X): # split data into train/test groups, 5 times\n",
        "        clf.fit(X[train], y[train]) # fit the classifier, passed is as clf.\n",
        "        result += scorefunc(clf, X[test], y[test]) # evaluate score function on held-out data\n",
        "    return result / nfold # average\n",
        "\n",
        "def log_likelihood(clf_nBayes, x, y):\n",
        "    prob = clf_nBayes.predict_log_proba(x)\n",
        "    toxic = y == 1\n",
        "    non_toxic = ~toxic\n",
        "    return prob[non_toxic, 0].sum() + prob[toxic, 1].sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7Md-hzdQSz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "itrain, itest = train_test_split(range(unpickled_df.shape[0]), train_size=0.7)\n",
        "mask=np.ones(unpickled_df.shape[0], dtype='int')\n",
        "mask[itrain]=0\n",
        "mask[itest]=1\n",
        "mask = (mask==1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1pIFCVGRV4L",
        "colab_type": "code",
        "outputId": "46bc1315-b231-44e6-9f49-159882fa408a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        }
      },
      "source": [
        "#the grid of parameters to search over\n",
        "alphas = [0, .1, 1, 5, 10, 50]\n",
        "min_dfs = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1]\n",
        "\n",
        "#Find the best value for alpha and min_df, and the best classifier\n",
        "best_alpha = None\n",
        "best_min_df = None\n",
        "maxscore=-np.inf\n",
        "for alpha in alphas:\n",
        "    for min_df in min_dfs:         \n",
        "        vectorizer = CountVectorizer(min_df = min_df)       \n",
        "        Xthis, ythis, vectorizer = make_xy(unpickled_df)\n",
        "        Xtrainthis=Xthis[mask]\n",
        "        ytrainthis=ythis[mask]\n",
        "\n",
        "        clf_nBayes = MultinomialNB(alpha=alpha)\n",
        "        cvscore = cv_score(clf_nBayes, Xtrainthis, ytrainthis, log_likelihood)\n",
        "\n",
        "        if cvscore > maxscore:\n",
        "            maxscore = cvscore\n",
        "            best_alpha, best_min_df = alpha, min_df"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/naive_bayes.py:507: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
            "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uK9RQp14R2nF",
        "colab_type": "code",
        "outputId": "86763e59-be94-49af-beaa-0268863be0f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(\"alpha: %f\" % best_alpha)\n",
        "print(\"min_df: %f\" % best_min_df)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "alpha: 0.100000\n",
            "min_df: 0.000010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewj5faJB-pcq",
        "colab_type": "code",
        "outputId": "684df3e1-216d-439d-be24-cee441f391cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "best_alpha = 0.100000\n",
        "best_min_df = 0.000010\n",
        "\n",
        "vectorizer = CountVectorizer(min_df=best_min_df)\n",
        "X, y, vectorizer = make_xy(unpickled_df, vectorizer)\n",
        "xtrain=X[mask]\n",
        "ytrain=y[mask]\n",
        "xtest=X[~mask]\n",
        "ytest=y[~mask]\n",
        "\n",
        "clf = MultinomialNB(alpha=best_alpha).fit(xtrain, ytrain)\n",
        "\n",
        "# Print the accuracy on the test and training dataset\n",
        "training_accuracy = clf.score(xtrain, ytrain)\n",
        "test_accuracy = clf.score(xtest, ytest)\n",
        "\n",
        "print(\"Accuracy on training data: {:2f}\".format(training_accuracy))\n",
        "print(\"Accuracy on test data:     {:2f}\".format(test_accuracy))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy on training data: 0.898316\n",
            "Accuracy on test data:     0.888490\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ebb0e2cb-fa48-4b8f-c1e9-e0d05381faa6",
        "id": "ZpXCsAqc_RVd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "# Fit the model on the trainng data for NB\n",
        "clf.fit(xtrain, ytrain)\n",
        "\n",
        "# Print the accuracy from the testing data.\n",
        "y_predict_test = clf.predict(xtest)\n",
        "print(\"\\n\")\n",
        "print(\"[Test] Accuracy score (y_predict_test, ytest):\",accuracy_score(y_predict_test, ytest))\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"[Test] Accuracy score: (ytest, y_predict_test)\",accuracy_score(ytest, y_predict_test))\n",
        "\n",
        "y_predict_training = clf.predict(xtrain)\n",
        "print(\"\\n\")\n",
        "print(\"[Training] Accuracy score: (ytrain, y_predict_training)\",accuracy_score(ytrain, y_predict_training))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[Test] Accuracy score (y_predict_test, ytest): 0.8884899688224972\n",
            "\n",
            "\n",
            "[Test] Accuracy score: (ytest, y_predict_test) 0.8884899688224972\n",
            "\n",
            "\n",
            "[Training] Accuracy score: (ytrain, y_predict_training) 0.8983162284403551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d87a90ee-1a82-43b6-c197-922a536a055d",
        "id": "CadboD-f_RVs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "# more comprehensive performance analysis for NB\n",
        "\n",
        "target_names = ['Non-Toxic', 'Toxic']\n",
        "\n",
        "print(\"[Training Classification Report]\")\n",
        "print(classification_report(ytrain, y_predict_training, target_names=target_names))\n",
        "\n",
        "print(\"[Test Classification Report]\")\n",
        "print(classification_report(ytest, y_predict_test, target_names=target_names))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Training Classification Report]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Toxic       0.97      0.91      0.94    498269\n",
            "       Toxic       0.42      0.71      0.53     43194\n",
            "\n",
            "    accuracy                           0.90    541463\n",
            "   macro avg       0.70      0.81      0.73    541463\n",
            "weighted avg       0.93      0.90      0.91    541463\n",
            "\n",
            "[Test Classification Report]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Toxic       0.97      0.91      0.94   1162271\n",
            "       Toxic       0.38      0.62      0.47    101140\n",
            "\n",
            "    accuracy                           0.89   1263411\n",
            "   macro avg       0.67      0.77      0.70   1263411\n",
            "weighted avg       0.92      0.89      0.90   1263411\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g2Ruc9OcATq4"
      },
      "source": [
        "Looking at the results of the hypertuned Naive Bayes, we see that for non-toxic both precision and recall, ~0.97 and ~0.92 respectively, are approximately the same between the train and test set. This means our model was accurate in identifying 97% of actual positives and mislabeling only 3%. Similarly, precision is ~92% showing that of the predicted positives, 8% were actually toxic. \n",
        "\n",
        "However, in predicting toxic comments, the model didn't do as well which is similar to the results of the logistic regression. For Naive Bayes, the trade off is flipped from the logistic regression. The train set's precision is a 42% with a recall of 71%. The train set mislabeled over 50% of the data it said was toxic. Of the identified actual toxic comments, Naive Bayes identified 71% versus 49% for logisitc regression. The test set performed worse with a precision of 38% and a recall of 62%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPbX6lOhsDe0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate roc curve\n",
        "fpr, tpr, thresholds = roc_curve(ytrain, y_predict_training)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhuLwITDxOnm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19490e5b-8a30-4c8b-f0f7-3a6b7fcfcd33"
      },
      "source": [
        "# calculate AUC\n",
        "auc = roc_auc_score(ytrain, y_predict_training)\n",
        "print('AUC: %.3f' % auc)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.811\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ-gjBr-rddc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "3d861175-1066-4238-f9a1-278f9525435f"
      },
      "source": [
        "# plot the roc curve for the model\n",
        "plt.plot(fpr, tpr, linestyle='--')\n",
        "\n",
        "# axis labels\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "plt.legend()\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ38hW3pvheQ",
        "colab_type": "text"
      },
      "source": [
        "A good measure of separability implying an excellent model is an AUC near 1. When AUC is 0.5, it means model has no class separation capacity whatsoever. Given an AUC of 0.81, it means there is 81% chance that model will be able to distinguish between positive class (toxic) and negative class (non-toxic).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q48KpfPgEYR7",
        "colab_type": "text"
      },
      "source": [
        "# Next Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2MvTQSfwtD2",
        "colab_type": "text"
      },
      "source": [
        "To determine if my theory of bias due to class imbalance holds true, I will be creating a training set with equal size classes between toxic and non-toxic. In doing so, I can test my theory of imbalance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA2mqiYLxPv8",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DnvWwS6k8Yz",
        "colab_type": "text"
      },
      "source": [
        "Recall - the ability of a model to find all the relevant cases within a dataset. Recall can be thought as of a model’s ability to find all the data points of interest in a dataset - correct results of the results that SHOULD HAVE been returned\n",
        "\n",
        "In the case of recall, when we increase the recall, we decrease the precision\n",
        "\n",
        "Precision - the ability of a classification model to identify only the relevant data points - correct results of results returned\n",
        "\n",
        "ROC curve?? quantify a model’s ROC curve by calculating the total Area Under the Curve (AUC), a metric which falls between 0 and 1 with a higher number indicating better classification performance. In the graph above, the AUC for the blue curve will be greater than that for the red curve, meaning the blue model is better at achieving a blend of precision and recall. A random classifier (the black line) achieves an AUC of 0.5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_qNuwUixSxY",
        "colab_type": "text"
      },
      "source": [
        "# Notes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pB9JaYvyOJNA",
        "colab_type": "text"
      },
      "source": [
        "Next Round:\n",
        "results for larger class - good\n",
        "results for smaller class - very bad\n",
        "\n",
        "step 1\n",
        "can do exploration of results to find \n",
        "certain tokens that are mislabeled to see ones that are shifting precisio recall\n",
        "\n",
        "coeff of logisitic reg\n",
        "sort in 2 list - 1) coeff w/ large abs val (pos) - toxic, 2) coeff w/ large abs val (neg) - non toxic\n",
        "\n",
        "2)\n",
        "in training set, have dist of toxic/non-toxic\n",
        "- take random sample of non-toxic training that is same size of toxic then run logistic regression training on it\n",
        "\n",
        "\n",
        "techniques aimed at imbalance logistic regressions\n",
        "- post baseline"
      ]
    }
  ]
}