{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modeling",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBCvmtGfo-Th",
        "colab_type": "text"
      },
      "source": [
        "# Springboard--DSC Program\n",
        "\n",
        "# Capstone Project 1 - Regression\n",
        "### by Ellen A. Savoye"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8excymRso7jd",
        "colab_type": "code",
        "outputId": "b437e032-fd45-4eef-e51b-c4716acc3848",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CyXoO9F6P983"
      },
      "source": [
        "# Import packages and data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9bv0hBza7DG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !pip install wordcloud\n",
        "# !pip install kaggle\n",
        "# !pip install spacy\n",
        "# !pip install swifter\n",
        "# !pip install tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V000gO_ZTLla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "from collections import Counter\n",
        "\n",
        "# libraries for NLP\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "import sklearn.model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy import stats\n",
        "# from scipy.stats import pearsonr\n",
        "\n",
        "# libraries for getting and moving data\n",
        "import os\n",
        "from os import path\n",
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# for Images\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_wKFpFJbDNl",
        "colab_type": "code",
        "outputId": "f6876ade-8eed-48d8-f992-5e6d3baecd76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# google colab only\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UStVLS0nbGO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# necessary dependencies for text pre-processing\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm', parse=True, tag=True, entity=True)\n",
        "#nlp_vec = spacy.load('en_vecs', parse = True, tag=True, #entity=True)\n",
        "tokenizer = ToktokTokenizer()\n",
        "stopword_list = nltk.corpus.stopwords.words('english')\n",
        "stopword_list.remove('no')\n",
        "stopword_list.remove('not')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg16C-vsbIAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set directories\n",
        "# Google Colab\n",
        "src = \"/content/drive/My Drive/DS-Capstone_1/Code/\"\n",
        "dst = \"/content/drive/My Drive/DS-Capstone_1/Data/\"\n",
        "\n",
        "# Local computer\n",
        "# src = \"C:\\\\Users\\\\ellen\\\\Documents\\\\GitHub\\\\Data_Science_Career_Track\\\\Capstone_1\\\\Code\\\\\"\n",
        "# dst = \"C:\\\\Users\\\\ellen\\\\Documents\\\\GitHub\\\\Data_Science_Career_Track\\\\Capstone_1\\\\Data\\\\\"\n",
        "\n",
        "# Work computer\n",
        "# src = \"C:\\\\Users\\\\esavoye\\\\Documents\\\\GitHub\\\\Data_Science_Career_Track\\\\Capstone_1\\\\Code\\\\\"\n",
        "# dst = \"C:\\\\Users\\\\esavoye\\\\Documents\\\\GitHub\\\\Data_Science_Career_Track\\\\Capstone_1\\\\Data\\\\\"\n",
        "\n",
        "# Computer path\n",
        "# unpickled_df = pd.read_pickle(dst + '/full_data_w_features.pkl')\n",
        "# unpickled_df_slimmed = pd.read_pickle(dst + '/slimmed_data_w_features.pkl')\n",
        "\n",
        "# Colab path\n",
        "unpickled_df = pd.read_pickle(dst + 'full_data_w_features.pkl')\n",
        "unpickled_df_slimmed = pd.read_pickle(dst + 'slimmed_data_w_features.pkl')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXC35_ykQd0X",
        "colab_type": "text"
      },
      "source": [
        "# Regression - CountVectorizer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSWykPdfR4yJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# grab text field\n",
        "cleaned_text = unpickled_df_slimmed.clean_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT91eWcoQm1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create an object of class - Count_Vectorizer\n",
        "vectorizer = CountVectorizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmKKr-ptSTsL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9d2f9d39-0520-407b-bb5f-468d6279013b"
      },
      "source": [
        "# call `fit_transform` to build the vocabulary and to convert text to a bag of words\n",
        "x = vectorizer.fit_transform(cleaned_text)\n",
        "type(x)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse.csr.csr_matrix"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltz3ypR6SnUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inputs:\n",
        "#         critics: a Pandas dataframe that contains the dataset.\n",
        "#         In particular, this dataframe is expected to have a column \n",
        "#         called 'quote', and critics.quote is a Series containing\n",
        "#         all documents, which is this case are movie reviews.\n",
        "#\n",
        "#         vectorizer: is expected to be an object of a class from\n",
        "#         sklearn.feature_extraction.text, (*)\n",
        "#         or None, in which case, per the code below, is constructed\n",
        "#         according to class CountVectorizer.\n",
        "#\n",
        "# Outputs:\n",
        "#         X: document-term matrix associated with critics.quote,\n",
        "#         according to the vectorization implemented by object \n",
        "#         vectorizer.\n",
        "#\n",
        "#         y: this is the label vector, such that y[i] is the label\n",
        "#         associated with document i, encoded according to row i of X\n",
        "#\n",
        "#         vectorizer: vectorizer_object object built\n",
        "#**************************************************************************\n",
        "def make_xy(unpickled_df_slimmed, vectorizer=None):\n",
        "    if vectorizer is None:\n",
        "        vectorizer = CountVectorizer()\n",
        "    X = vectorizer.fit_transform(unpickled_df_slimmed.clean_text)\n",
        "    X = X.tocsc()\n",
        "    y = (unpickled_df_slimmed.target_binary == 1).values.astype(np.int)\n",
        "    return X, y, vectorizer\n",
        "\n",
        "X, y, vectorizer = make_xy(unpickled_df_slimmed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTY8moUZaEuY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4150e9ad-010a-4200-bba3-a48bd68ce18a"
      },
      "source": [
        "xtrain, xtest, ytrain, ytest = train_test_split(X, y)\n",
        "clf = MultinomialNB().fit(xtrain, ytrain)\n",
        "print(\"MN Accuracy: %0.2f%%\" % (100 * clf.score(xtest, ytest)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MN Accuracy: 88.32%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}