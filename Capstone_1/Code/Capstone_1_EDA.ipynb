{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Springboard--DSC Program\n",
    "\n",
    "# Capstone Project 1 - Exploratory Data Analysis \n",
    "### by Ellen A. Savoye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, we cleaned up the text data by converting to lower case, and removing stopwords, emojis, emoticons, punctuation, and special characters. The output was pickled for further use. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# libraries for NLP\n",
    "import spacy\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "import string\n",
    "from string import punctuation\n",
    "\n",
    "from emot.emo_unicode import UNICODE_EMO, EMOTICONS\n",
    "import swifter\n",
    "\n",
    "# libraries for getting and moving data\n",
    "import os\n",
    "from os import path\n",
    "import shutil\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# from kaggle.api.kaggle_api_extended import KaggleApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# necessary dependencies for text pre-processing\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', parse=True, tag=True, entity=True)\n",
    "#nlp_vec = spacy.load('en_vecs', parse = True, tag=True, #entity=True)\n",
    "tokenizer = ToktokTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directories\n",
    "# src = \"C:\\\\Users\\\\ellen\\\\Documents\\\\GitHub\\\\Data_Science_Career_Track\\\\Capstone_1\\\\Code\\\\\"\n",
    "# dst = \"C:\\\\Users\\\\ellen\\\\Documents\\\\GitHub\\\\Data_Science_Career_Track\\\\Capstone_1\\\\Data\\\\\"\n",
    "\n",
    "# Work computer\n",
    "src = \"C:\\\\Users\\\\esavoye\\\\Documents\\\\GitHub\\\\Data_Science_Career_Track\\\\Capstone_1\\\\Code\\\\\"\n",
    "dst = \"C:\\\\Users\\\\esavoye\\\\Documents\\\\GitHub\\\\Data_Science_Career_Track\\\\Capstone_1\\\\Data\\\\\"\n",
    "\n",
    "# Create pickle file for use in the future\n",
    "\n",
    "unpickled_df = pd.read_pickle(dst + '/cleaned_train_data.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions to ask:\n",
    "1) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
