{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Springboard--DSC Program\n",
    "\n",
    "# Capstone Project 1 - Data Wrangling \n",
    "### by Ellen A. Savoye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data collected is from a Kaggle competition, Jigsaw Unintended Bias in Toxicity Classification, via the Kaggle API. Of the 7 files in the zipped data, we will be focusing on the 'train' data. The original 'train' data is comprised of 45 columns containing information on toxicity and identity labels, comments, and metadata. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install kaggle\n",
    "# !pip install spacy\n",
    "# !pip install spacymoji\n",
    "# !pip install emot\n",
    "# !pip install demoji\n",
    "# !pip install swifter\n",
    "# !pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# libraries for NLP\n",
    "import spacy\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "import string\n",
    "from string import punctuation\n",
    "\n",
    "from emot.emo_unicode import UNICODE_EMO, EMOTICONS\n",
    "import swifter\n",
    "\n",
    "# libraries for getting and moving data\n",
    "import os\n",
    "from os import path\n",
    "import shutil\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# from kaggle.api.kaggle_api_extended import KaggleApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# necessary dependencies for text pre-processing\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', parse=True, tag=True, entity=True)\n",
    "#nlp_vec = spacy.load('en_vecs', parse = True, tag=True, #entity=True)\n",
    "tokenizer = ToktokTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is already downloaded\n"
     ]
    }
   ],
   "source": [
    "# Set directories\n",
    "# src = \"C:\\\\Users\\\\ellen\\\\Documents\\\\GitHub\\\\Data_Science_Career_Track\\\\Capstone_1\\\\Code\\\\\"\n",
    "# dst = \"C:\\\\Users\\\\ellen\\\\Documents\\\\GitHub\\\\Data_Science_Career_Track\\\\Capstone_1\\\\Data\\\\\"\n",
    "\n",
    "# Work computer\n",
    "src = \"C:\\\\Users\\\\esavoye\\\\Documents\\\\GitHub\\\\Data_Science_Career_Track\\\\Capstone_1\\\\Code\\\\\"\n",
    "dst = \"C:\\\\Users\\\\esavoye\\\\Documents\\\\GitHub\\\\Data_Science_Career_Track\\\\Capstone_1\\\\Data\\\\\"\n",
    "\n",
    "kaggle_comp_name = 'jigsaw-unintended-bias-in-toxicity-classification'\n",
    "zipfile_name = kaggle_comp_name + '.zip'\n",
    "\n",
    "csv_file = [i for i in os.listdir(dst) if i.startswith(\"train\") and path.isfile(path.join(dst, i))]\n",
    "zip_file = [i for i in os.listdir(dst) if i.startswith(\"jigsaw\") and path.isfile(path.join(dst, i))]\n",
    "\n",
    "if zip_file[0] != zipfile_name:\n",
    "    #Import data from Kaggle API\n",
    "    api = KaggleApi()\n",
    "    api.authenticate()\n",
    "    files = api.competition_download_files(kaggle_comp_name)\n",
    "    \n",
    "    # Move the jigsaw zip file to the Data folder\n",
    "    files = [i for i in os.listdir(src) if i.startswith(\"jigsaw\") and path.isfile(path.join(src, i))]\n",
    "    for f in files:\n",
    "        shutil.move(path.join(src, f), dst)\n",
    "    \n",
    "    # Check if Train data is already extracted\n",
    "    if csv_file != 'train.csv':\n",
    "        with ZipFile(dst + zipfile_name, 'r') as zipObj:\n",
    "            # Extract all the contents of zip file in current directory\n",
    "            print(zipObj.namelist())\n",
    "            zipObj.extract('train.csv', path = dst)\n",
    "else:\n",
    "    print('Data is already downloaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 1804874\n",
      "['id', 'target', 'comment_text', 'severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat', 'asian', 'atheist', 'bisexual', 'black', 'buddhist', 'christian', 'female', 'heterosexual', 'hindu', 'homosexual_gay_or_lesbian', 'intellectual_or_learning_disability', 'jewish', 'latino', 'male', 'muslim', 'other_disability', 'other_gender', 'other_race_or_ethnicity', 'other_religion', 'other_sexual_orientation', 'physical_disability', 'psychiatric_or_mental_illness', 'transgender', 'white', 'created_date', 'publication_id', 'parent_id', 'article_id', 'rating', 'funny', 'wow', 'sad', 'likes', 'disagree', 'sexual_explicit', 'identity_annotator_count', 'toxicity_annotator_count']\n"
     ]
    }
   ],
   "source": [
    "# Read in the train dataset\n",
    "csv_filename = 'train.csv'\n",
    "train_data = pd.read_csv(dst + csv_filename, low_memory=False)\n",
    "\n",
    "# Output the number of rows\n",
    "print(\"Total rows: {0}\".format(len(train_data)))\n",
    "\n",
    "# See which headers are available\n",
    "print(list(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The metadata from Civil Comments platform is contained in the following columns: created_date, publication_id, parent_id, article_id, rating, funny, wow, sad, likes, and disagree.\n",
    "\n",
    "I will be keeping these fields in for further exploration and possible use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "id                                           0\n",
      "target                                       0\n",
      "comment_text                                 0\n",
      "severe_toxicity                              0\n",
      "obscene                                      0\n",
      "identity_attack                              0\n",
      "insult                                       0\n",
      "threat                                       0\n",
      "asian                                  1399744\n",
      "atheist                                1399744\n",
      "bisexual                               1399744\n",
      "black                                  1399744\n",
      "buddhist                               1399744\n",
      "christian                              1399744\n",
      "female                                 1399744\n",
      "heterosexual                           1399744\n",
      "hindu                                  1399744\n",
      "homosexual_gay_or_lesbian              1399744\n",
      "intellectual_or_learning_disability    1399744\n",
      "jewish                                 1399744\n",
      "latino                                 1399744\n",
      "male                                   1399744\n",
      "muslim                                 1399744\n",
      "other_disability                       1399744\n",
      "other_gender                           1399744\n",
      "other_race_or_ethnicity                1399744\n",
      "other_religion                         1399744\n",
      "other_sexual_orientation               1399744\n",
      "physical_disability                    1399744\n",
      "psychiatric_or_mental_illness          1399744\n",
      "transgender                            1399744\n",
      "white                                  1399744\n",
      "created_date                                 0\n",
      "publication_id                               0\n",
      "parent_id                               778646\n",
      "article_id                                   0\n",
      "rating                                       0\n",
      "funny                                        0\n",
      "wow                                          0\n",
      "sad                                          0\n",
      "likes                                        0\n",
      "disagree                                     0\n",
      "sexual_explicit                              0\n",
      "identity_annotator_count                     0\n",
      "toxicity_annotator_count                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#function for counting null records:\n",
    "def num_missing(x):\n",
    "    return sum(x.isnull())\n",
    "\n",
    "#Applying per column:\n",
    "print(\"Missing values per column:\")\n",
    "print(train_data.apply(num_missing, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                      0.0\n",
      "target                                  0.0\n",
      "comment_text                            0.0\n",
      "severe_toxicity                         0.0\n",
      "obscene                                 0.0\n",
      "identity_attack                         0.0\n",
      "insult                                  0.0\n",
      "threat                                  0.0\n",
      "asian                                  77.6\n",
      "atheist                                77.6\n",
      "bisexual                               77.6\n",
      "black                                  77.6\n",
      "buddhist                               77.6\n",
      "christian                              77.6\n",
      "female                                 77.6\n",
      "heterosexual                           77.6\n",
      "hindu                                  77.6\n",
      "homosexual_gay_or_lesbian              77.6\n",
      "intellectual_or_learning_disability    77.6\n",
      "jewish                                 77.6\n",
      "latino                                 77.6\n",
      "male                                   77.6\n",
      "muslim                                 77.6\n",
      "other_disability                       77.6\n",
      "other_gender                           77.6\n",
      "other_race_or_ethnicity                77.6\n",
      "other_religion                         77.6\n",
      "other_sexual_orientation               77.6\n",
      "physical_disability                    77.6\n",
      "psychiatric_or_mental_illness          77.6\n",
      "transgender                            77.6\n",
      "white                                  77.6\n",
      "created_date                            0.0\n",
      "publication_id                          0.0\n",
      "parent_id                              43.1\n",
      "article_id                              0.0\n",
      "rating                                  0.0\n",
      "funny                                   0.0\n",
      "wow                                     0.0\n",
      "sad                                     0.0\n",
      "likes                                   0.0\n",
      "disagree                                0.0\n",
      "sexual_explicit                         0.0\n",
      "identity_annotator_count                0.0\n",
      "toxicity_annotator_count                0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Find percent of missing values for each column instead of number of records\n",
    "\n",
    "percent_missing = train_data.isnull().sum() * 100 / len(train_data)\n",
    "print(round(percent_missing,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                       int64\n",
       "target                                 float64\n",
       "comment_text                            object\n",
       "severe_toxicity                        float64\n",
       "obscene                                float64\n",
       "identity_attack                        float64\n",
       "insult                                 float64\n",
       "threat                                 float64\n",
       "asian                                  float64\n",
       "atheist                                float64\n",
       "bisexual                               float64\n",
       "black                                  float64\n",
       "buddhist                               float64\n",
       "christian                              float64\n",
       "female                                 float64\n",
       "heterosexual                           float64\n",
       "hindu                                  float64\n",
       "homosexual_gay_or_lesbian              float64\n",
       "intellectual_or_learning_disability    float64\n",
       "jewish                                 float64\n",
       "latino                                 float64\n",
       "male                                   float64\n",
       "muslim                                 float64\n",
       "other_disability                       float64\n",
       "other_gender                           float64\n",
       "other_race_or_ethnicity                float64\n",
       "other_religion                         float64\n",
       "other_sexual_orientation               float64\n",
       "physical_disability                    float64\n",
       "psychiatric_or_mental_illness          float64\n",
       "transgender                            float64\n",
       "white                                  float64\n",
       "created_date                            object\n",
       "publication_id                           int64\n",
       "parent_id                              float64\n",
       "article_id                               int64\n",
       "rating                                  object\n",
       "funny                                    int64\n",
       "wow                                      int64\n",
       "sad                                      int64\n",
       "likes                                    int64\n",
       "disagree                                 int64\n",
       "sexual_explicit                        float64\n",
       "identity_annotator_count                 int64\n",
       "toxicity_annotator_count                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data type of each column\n",
    "\n",
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rejected', 'approved'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.rating.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1804874, 45)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 45 columns in the train dataframe. Of those 45, only three columns, 'comment_text', 'created_date', and 'rating', are objects. The remaining 42 are either float64 or int64. These columns are non-categorical. 'Comment_text' is categorical containing the individual comments that we need to analyze. 'Created_date' contains the original date the comments were created. 'Rating' is a categorical containing two values: rejected or approved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    This is so cool. It's like, 'would you want yo...\n",
       "1    Thank you!! This would make my life a lot less...\n",
       "2    This is such an urgent design problem; kudos t...\n",
       "3    Is this something I'll be able to install on m...\n",
       "4                 haha you guys are a bunch of losers.\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.comment_text.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.89361702, 0.66666667, ..., 0.87726476, 0.01116838,\n",
       "       0.87008821])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View unique records in a particular column\n",
    "\n",
    "#sorted(train_data.target.unique())\n",
    "train_data.target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for blank string records\n",
    "np.where(train_data.applymap(lambda x: x == ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum value: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                                                                                 59848\n",
       "target                                                                                 0\n",
       "comment_text                           \u0010Canada is north of the USA border,  its colde...\n",
       "severe_toxicity                                                                        0\n",
       "obscene                                                                                0\n",
       "identity_attack                                                                        0\n",
       "insult                                                                                 0\n",
       "threat                                                                                 0\n",
       "asian                                                                                  0\n",
       "atheist                                                                                0\n",
       "bisexual                                                                               0\n",
       "black                                                                                  0\n",
       "buddhist                                                                               0\n",
       "christian                                                                              0\n",
       "female                                                                                 0\n",
       "heterosexual                                                                           0\n",
       "hindu                                                                                  0\n",
       "homosexual_gay_or_lesbian                                                              0\n",
       "intellectual_or_learning_disability                                                    0\n",
       "jewish                                                                                 0\n",
       "latino                                                                                 0\n",
       "male                                                                                   0\n",
       "muslim                                                                                 0\n",
       "other_disability                                                                       0\n",
       "other_gender                                                                           0\n",
       "other_race_or_ethnicity                                                                0\n",
       "other_religion                                                                         0\n",
       "other_sexual_orientation                                                               0\n",
       "physical_disability                                                                    0\n",
       "psychiatric_or_mental_illness                                                          0\n",
       "transgender                                                                            0\n",
       "white                                                                                  0\n",
       "created_date                                               2015-09-29 10:50:41.987077+00\n",
       "publication_id                                                                         2\n",
       "parent_id                                                                          61006\n",
       "article_id                                                                          2006\n",
       "rating                                                                          approved\n",
       "funny                                                                                  0\n",
       "wow                                                                                    0\n",
       "sad                                                                                    0\n",
       "likes                                                                                  0\n",
       "disagree                                                                               0\n",
       "sexual_explicit                                                                        0\n",
       "identity_annotator_count                                                               0\n",
       "toxicity_annotator_count                                                               3\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the range of numerical columns\n",
    "print('Minimum value: ')\n",
    "train_data.iloc[:,:].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum value: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id                                                           6334010\n",
       "target                                                             1\n",
       "comment_text                                         🤣gotta love it!\n",
       "severe_toxicity                                                    1\n",
       "obscene                                                            1\n",
       "identity_attack                                                    1\n",
       "insult                                                             1\n",
       "threat                                                             1\n",
       "asian                                                              1\n",
       "atheist                                                            1\n",
       "bisexual                                                           1\n",
       "black                                                              1\n",
       "buddhist                                                           1\n",
       "christian                                                          1\n",
       "female                                                             1\n",
       "heterosexual                                                       1\n",
       "hindu                                                              1\n",
       "homosexual_gay_or_lesbian                                          1\n",
       "intellectual_or_learning_disability                                1\n",
       "jewish                                                             1\n",
       "latino                                                             1\n",
       "male                                                               1\n",
       "muslim                                                             1\n",
       "other_disability                                                 0.6\n",
       "other_gender                                                    0.75\n",
       "other_race_or_ethnicity                                            1\n",
       "other_religion                                                     1\n",
       "other_sexual_orientation                                        0.75\n",
       "physical_disability                                                1\n",
       "psychiatric_or_mental_illness                                      1\n",
       "transgender                                                        1\n",
       "white                                                              1\n",
       "created_date                           2017-11-11 01:01:10.822969+00\n",
       "publication_id                                                   115\n",
       "parent_id                                                6.33396e+06\n",
       "article_id                                                    399541\n",
       "rating                                                      rejected\n",
       "funny                                                            102\n",
       "wow                                                               21\n",
       "sad                                                               31\n",
       "likes                                                            300\n",
       "disagree                                                         187\n",
       "sexual_explicit                                                    1\n",
       "identity_annotator_count                                        1866\n",
       "toxicity_annotator_count                                        4936\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Maximum value: ')\n",
    "train_data.iloc[:,:].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toxicity and identity labels range from 0.0-1.0. The value represents the fraction of raters who believed the label fit the comment. Toxicity labels do not have any missing values. According to the competition details, a subset of comments have been labeled with a variety of identity attributes that have been mentioned in the comment. As such, every identity label is missing ~78% of the values per column. The subset comprises approximately 22% of the data. \n",
    "\n",
    "Two examples of how labeling works are as follows:\n",
    "Example 1: \n",
    "    - Comment: I'm a white woman in my late 60's and believe me, they are not too crazy about me either!!\n",
    "    - Toxicity Labels: All 0.0\n",
    "    - Identity Mention Labels: female: 1.0, white: 1.0 (all others 0.0)\n",
    "\n",
    "Example 2: \n",
    "    - Comment: Continue to stand strong LGBT community. Yes, indeed, you'll overcome and you have.\n",
    "    - Toxicity Labels: All 0.0\n",
    "    - Identity Mention Labels: homosexual_gay_or_lesbian: 0.8, bisexual: 0.6, transgender: 0.3 (all others 0.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Target' is the toxicity label. 'Severe_toxicity', 'obscene', 'identity_attack', 'insult', 'threat', and 'sexual_explicit' are toxicity sub types. All toxicity labels can be converted to categorical variables by using >= 0.5 as a positive indicator (1). \n",
    "\n",
    "Aside from 'id', 'comment_text', 'identity_annotator_count' and 'toxicity_annotator_count', the same conversion can be applied to the remaining identity columns. 'Id' is a unique identifier for each comment but may not hold value to keep in the data frame. 'Identity_annotator_count' and 'toxicity_annotator_count' are metadata columns from Jigsaw and may not hold value either. However, I'm not removing them until I do my exploratory data analysis to determine if they offer valuable insights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Pre-processing and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the size of the original dataset, ~1.8M records, I took a 25% random sample to quantify and test some of the text cleaning and pre-processing ideas: testing for punctuation, emoticons, emoji, accented words, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a smaller 10% random sample data frame to test text cleaning/pre-processing\n",
    "\n",
    "subset_train_data = train_data.sample(frac=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180487, 45)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_train_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to considering removing emojis and emoticons, I need to see how frequently they occur in my data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d105dc052f44ccfada9a3fd297f0218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=180487.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#extracting the emojis\n",
    "emojis_list = map(lambda x: ''.join(x.split()), UNICODE_EMO.keys())\n",
    "r = re.compile('|'.join(re.escape(p) for p in emojis_list))\n",
    "subset_train_data['emoji'] = subset_train_data['comment_text'].str.findall(r)\n",
    "#Emoji count\n",
    "subset_train_data['emoji_count'] = subset_train_data['emoji'].swifter.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emoji percentage in sample data:  0.4117 %\n"
     ]
    }
   ],
   "source": [
    "print('Emoji percentage in sample data: ', round(subset_train_data['emoji_count'].sum() / subset_train_data['emoji_count'].count() * 100,4), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d7191e755842a6bc3cbb99f0faf4a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=180487.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#extracting the emoticons\n",
    "emoticons_list = map(lambda x: ''.join(x.split()), EMOTICONS.keys())\n",
    "r = re.compile('|'.join(re.escape(p) for p in emoticons_list))\n",
    "subset_train_data['emoticons'] = subset_train_data['comment_text'].str.findall(r)\n",
    "#Emoji count\n",
    "subset_train_data['emoticons_count'] = subset_train_data['emoticons'].swifter.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emoticons percentage in sample data:  4.0097 %\n"
     ]
    }
   ],
   "source": [
    "print('Emoticons percentage in sample data: ', round(subset_train_data['emoticons_count'].sum() / subset_train_data['emoticons_count'].count() * 100,4), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My sample data contains emoticons in approximately 4% of the data and emoji in .5%. Given the minimal presence of both emoji and emoticons, I'll be removing them both along with punctuation before moving on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to remove emoji and emoticons\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)   \n",
    "\n",
    "def remove_emoticons(text):\n",
    "    emoticon_pattern = re.compile(u'(' + u'|'.join(k for k in EMOTICONS) + u')')\n",
    "    return emoticon_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d600668f1d6f4e5cb75d4fcf21de83c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=180487.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "subset_train_data['comment_text_no_emo'] = subset_train_data['comment_text'].swifter.apply(remove_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a545e343ea348eaae9a9ffdcc23c194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=180487.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "subset_train_data['comment_text_no_emo'] = subset_train_data['comment_text_no_emo'].swifter.apply(remove_emoticons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With emoji and emoticons removed, we can remove punctuation, any remaining special characters, and convert to lowercase as we split our comments into individual words. I'm removing stop words on my subset of data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to strip punctuation\n",
    "def strip_punctuation(s):\n",
    "    return ''.join(c for c in s if c not in punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_train_data['comment_text_punct'] = subset_train_data['comment_text_no_emo'].swifter.apply(lambda x: strip_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1495173    What a DISGRACE\\nHERE THIS WILL CHEER YOU ALL ...\n",
       "980787                       June skies welcome home Hokulea\n",
       "1763540    They do have some famous scientists and even m...\n",
       "1496259    So far priests should listen to their people a...\n",
       "669486     So  has Wynne become a climate change denier  ...\n",
       "Name: comment_text_punct, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_train_data['comment_text_punct'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "339423    Keep up the good work Mr Putin You mean the KG...\n",
       "511599                                    Youre so straight\n",
       "425109    Are you making a statement or asking a questio...\n",
       "476594    Highly doubt it Conservatives dont need outsid...\n",
       "378440    Most people dont drink to get drunk  the only ...\n",
       "Name: comment_text_punct, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_train_data.comment_text_punct.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e895600305bf4c68804eeb72d4973a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=180487.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#convert to lower case\n",
    "subset_train_data['comment_text_lower'] = subset_train_data['comment_text_punct'].swifter.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find and remove any remaining non-alphanumeric characters\n",
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d100582fca6440409ff198067ba04643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=180487.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#remove non-alphanumeric characters remaining i.g. â€\n",
    "subset_train_data['comment_text_lower'] = subset_train_data['comment_text_lower'].swifter.apply(lambda x: remove_special_characters(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8355d0808f94ffeb265c61bcebc7737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=180487.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#split sentences into words\n",
    "subset_train_data['comment_text_words'] = subset_train_data['comment_text_lower'].swifter.apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "339423    [keep, up, the, good, work, mr, putin, you, me...\n",
       "511599                                [youre, so, straight]\n",
       "425109    [are, you, making, a, statement, or, asking, a...\n",
       "476594    [highly, doubt, it, conservatives, dont, need,...\n",
       "378440    [most, people, dont, drink, to, get, drunk, th...\n",
       "Name: comment_text_words, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_train_data['comment_text_words'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(list_of_words):\n",
    "    words = [w for w in list_of_words if not w in stop_words]\n",
    "    return words\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd73d3e42a50482facb52c3d04cf3dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Pandas Apply', max=180487.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# remove stop words \n",
    "subset_train_data['comment_text_words'] = subset_train_data['comment_text_words'].swifter.apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "339423    [keep, good, work, mr, putin, mean, kgb, man, ...\n",
       "511599                                    [youre, straight]\n",
       "425109    [making, statement, asking, question, poor, gr...\n",
       "476594    [highly, doubt, conservatives, dont, need, out...\n",
       "378440    [people, dont, drink, get, drunk, reason, smok...\n",
       "Name: comment_text_words, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_train_data['comment_text_words'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A by-product of removing the stop words is inadvertently changing the context of some of the comments. For example, \"...no one wants them to in the country anymore\" changes to \"'one', 'wants', 'country', 'anymore'\". The context has changed slightly. In the function below, I have the removal of stop words as False for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying cleaning to full data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ease, I'm creating a function that will apply each step of cleaning to my original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_corpus(corpus, emoji_removal=True, emoticon_removal=True, \n",
    "                     punctuation_removal=True, text_lower_case=True, special_char_removal=True, \n",
    "                     lemmatize=False, stopword_removal=False, remove_digits=False):\n",
    "    \n",
    "    normalized_corpus = []\n",
    "    # normalize each document in the corpus\n",
    "    for doc in corpus:\n",
    "        # remove emoji\n",
    "        if emoji_removal:\n",
    "            doc = remove_emoji(doc)\n",
    "        # remove emoticon\n",
    "        if emoticon_removal:\n",
    "            doc = remove_emoticons(doc)\n",
    "        # remove punctuation\n",
    "        if punctuation_removal:\n",
    "            doc = strip_punctuation(doc)\n",
    "        # lowercase the text    \n",
    "        if text_lower_case:\n",
    "            doc = doc.lower()\n",
    "        # remove extra newlines\n",
    "        doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',doc)\n",
    "        # lemmatize text\n",
    "#         if lemmatize_text:\n",
    "#             doc = lemmatize_text(doc)\n",
    "        # remove special characters and\\or digits    \n",
    "        if special_char_removal:\n",
    "            # insert spaces between special characters to isolate them    \n",
    "            special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "            doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
    "            doc = remove_special_characters(doc, remove_digits=remove_digits)  \n",
    "        # remove extra whitespace\n",
    "        doc = re.sub(' +', ' ', doc)\n",
    "        # remove stopwords\n",
    "        if stopword_removal:\n",
    "            doc = remove_stopwords(doc, is_lower_case=text_lower_case)\n",
    "            \n",
    "        normalized_corpus.append(doc)\n",
    "        \n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply function normalize_corpus to full comment_text data\n",
    "\n",
    "train_data['clean_text'] = normalize_corpus(train_data['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    this is so cool its like would you want your m...\n",
       "1    thank you this would make my life a lot less a...\n",
       "2    this is such an urgent design problem kudos to...\n",
       "3    is this something ill be able to install on my...\n",
       "4                  haha you guys are a bunch of losers\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create CSV with cleaned text column - 1.25 GB output\n",
    "\n",
    "# train_data.to_csv('cleaned_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data.head().to_csv('test1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset_train_data.head().to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided not to use lemmatization or POS tagging on my cleaned data. If I end up wanting to apply lemmatization or POS tagging, I will do so during or after exploratory data analysis (EDA). Tokenization will also happen during EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pickle file for use in the future\n",
    "\n",
    "train_data.to_pickle(dst + '/cleaned_train_data.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
