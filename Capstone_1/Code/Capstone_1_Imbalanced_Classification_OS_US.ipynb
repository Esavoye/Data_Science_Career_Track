{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capstone_1_Imbalanced_Classification_OS_US",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBCvmtGfo-Th",
        "colab_type": "text"
      },
      "source": [
        "# Springboard--DSC Program\n",
        "\n",
        "# Capstone Project 1 - Regression with SMOTE and Under-Sampling\n",
        "### by Ellen A. Savoye"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8excymRso7jd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "8c18a240-ae7e-43ae-a6cf-b77ba6037f5c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CyXoO9F6P983"
      },
      "source": [
        "# Import packages and data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9bv0hBza7DG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "outputId": "22cfd853-5e1e-4e4e-f2fe-ff6bed3c3be4"
      },
      "source": [
        "# !pip install wordcloud\n",
        "# !pip install kaggle\n",
        "# !pip install spacy\n",
        "# !pip install swifter\n",
        "# !pip install tqdm\n",
        "!pip install -U git+https://github.com/scikit-learn-contrib/imbalanced-learn.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/scikit-learn-contrib/imbalanced-learn.git\n",
            "  Cloning https://github.com/scikit-learn-contrib/imbalanced-learn.git to /tmp/pip-req-build-on0027x_\n",
            "  Running command git clone -q https://github.com/scikit-learn-contrib/imbalanced-learn.git /tmp/pip-req-build-on0027x_\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn==0.7.0) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn==0.7.0) (1.4.1)\n",
            "Collecting scikit-learn>=0.23\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/3a/eb8d7bbe28f4787d140bb9df685b7d5bf6115c0e2a969def4027144e98b6/scikit_learn-0.23.1-cp36-cp36m-manylinux1_x86_64.whl (6.8MB)\n",
            "\u001b[K     |████████████████████████████████| 6.9MB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn==0.7.0) (0.15.1)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/12/ec3f2e203afa394a149911729357aa48affc59c20e2c1c8297a60f33f133/threadpoolctl-2.1.0-py3-none-any.whl\n",
            "Building wheels for collected packages: imbalanced-learn\n",
            "  Building wheel for imbalanced-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imbalanced-learn: filename=imbalanced_learn-0.7.0-cp36-none-any.whl size=167059 sha256=cdd355011e9ac4c5183ae28974c2ab8577a5560b334edb4530ee2091472e698d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-llg6v7vm/wheels/6c/07/cf/38cb9b7cc9e6a0ac7648a80ec192b6f2d863405fb0049ac0ff\n",
            "Successfully built imbalanced-learn\n",
            "Installing collected packages: threadpoolctl, scikit-learn, imbalanced-learn\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: imbalanced-learn 0.4.3\n",
            "    Uninstalling imbalanced-learn-0.4.3:\n",
            "      Successfully uninstalled imbalanced-learn-0.4.3\n",
            "Successfully installed imbalanced-learn-0.7.0 scikit-learn-0.23.1 threadpoolctl-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V000gO_ZTLla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import itertools\n",
        "from collections import Counter\n",
        "\n",
        "# libraries for NLP\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
        "import sklearn.model_selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, roc_curve, roc_auc_score\n",
        "# ref: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html#sklearn.metrics.classification_report\n",
        "from six.moves import range\n",
        "import scipy.sparse\n",
        "\n",
        "# for imbalanced datasets\n",
        "import imblearn\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "# libraries for getting and moving data\n",
        "import os\n",
        "from os import path\n",
        "import shutil\n",
        "from zipfile import ZipFile\n",
        "\n",
        "# for Images\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as mtick\n",
        "%matplotlib inline"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hj-_jrTQkv9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set seed\n",
        "np.random.seed(42)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg16C-vsbIAv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set directories\n",
        "# Google Colab\n",
        "src = \"/content/drive/My Drive/DS-Capstone_1/Code/\"\n",
        "dst = \"/content/drive/My Drive/DS-Capstone_1/Data/\"\n",
        "\n",
        "# Local computer\n",
        "# src = \"C:\\\\Users\\\\ellen\\\\Documents\\\\GitHub\\\\Data_Science_Career_Track\\\\Capstone_1\\\\Code\\\\\"\n",
        "# dst = \"C:\\\\Users\\\\ellen\\\\Documents\\\\GitHub\\\\Data_Science_Career_Track\\\\Capstone_1\\\\Data\\\\\"\n",
        "\n",
        "# Work computer\n",
        "# src = \"C:\\\\Users\\\\esavoye\\\\Documents\\\\GitHub\\\\Data_Science_Career_Track\\\\Capstone_1\\\\Code\\\\\"\n",
        "# dst = \"C:\\\\Users\\\\esavoye\\\\Documents\\\\GitHub\\\\Data_Science_Career_Track\\\\Capstone_1\\\\Data\\\\\"\n",
        "\n",
        "# Computer path\n",
        "# unpickled_df = pd.read_pickle(dst + '/full_data_w_features.pkl')\n",
        "# unpickled_df_slimmed = pd.read_pickle(dst + '/slimmed_data_w_features.pkl')\n",
        "\n",
        "# Colab path\n",
        "unpickled_df = pd.read_pickle(dst + 'full_data_w_features.pkl')\n",
        "unpickled_df_slimmed = pd.read_pickle(dst + 'slimmed_data_w_features.pkl')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXC35_ykQd0X",
        "colab_type": "text"
      },
      "source": [
        "# Test Set & Countvectorizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnKuf6C82ZKc",
        "colab_type": "text"
      },
      "source": [
        "Both logistic regression and naive bayes take an X and y input. After applying countvectorizer, the data is split into train and test sets. I'm using stratify to keep the split given that only 8% of the data is labelled as toxic. Without using stratify, the imbalance in my data has the potential to be even worse. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSWykPdfR4yJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# grab text field\n",
        "cleaned_text = unpickled_df.clean_text"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wT91eWcoQm1H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create an object of class - Count_Vectorizer\n",
        "vectorizer = CountVectorizer()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmKKr-ptSTsL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e89de0b0-5799-4599-8737-2eba5b150c88"
      },
      "source": [
        "# call `fit_transform` to build the vocabulary and to convert text to a bag of words\n",
        "x = vectorizer.fit_transform(cleaned_text)\n",
        "type(x)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse.csr.csr_matrix"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltz3ypR6SnUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Inputs:\n",
        "#         critics: a Pandas dataframe that contains the dataset.\n",
        "#         In particular, this dataframe is expected to have a column \n",
        "#         called 'quote', and critics.quote is a Series containing\n",
        "#         all documents, which is this case are movie reviews.\n",
        "#\n",
        "#         vectorizer: is expected to be an object of a class from\n",
        "#         sklearn.feature_extraction.text, (*)\n",
        "#         or None, in which case, per the code below, is constructed\n",
        "#         according to class CountVectorizer.\n",
        "#\n",
        "# Outputs:\n",
        "#         X: document-term matrix associated with critics.quote,\n",
        "#         according to the vectorization implemented by object \n",
        "#         vectorizer.\n",
        "#\n",
        "#         y: this is the label vector, such that y[i] is the label\n",
        "#         associated with document i, encoded according to row i of X\n",
        "#\n",
        "#         vectorizer: vectorizer_object object built\n",
        "#**************************************************************************\n",
        "def make_xy(unpickled_df, vectorizer=None):\n",
        "    if vectorizer is None:\n",
        "        vectorizer = CountVectorizer()\n",
        "    X = vectorizer.fit_transform(unpickled_df.clean_text)\n",
        "    X = X.tocsc()\n",
        "    y = (unpickled_df.target_binary == 1).values.astype(np.int)\n",
        "    return X, y, vectorizer\n",
        "\n",
        "X, y, vectorizer = make_xy(unpickled_df)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ack0lE-KXnEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Create file for use in the future \n",
        "# scipy.sparse.save_npz(dst + '/X.pkl', X)\n",
        "# np.save(dst + '/y.npy', y)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irk_8VUa8-Yv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load files for use in the future \n",
        "X = scipy.sparse.load_npz(dst + 'X.pkl.npz')\n",
        "y = np.load(dst + 'y.npy')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bjvo5oKl4r2q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7ec274a4-b6f2-4676-b273-3496ef338d67"
      },
      "source": [
        "counter = Counter(y)\n",
        "print(counter)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({0: 1660540, 1: 144334})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKpvqnAuuvLS",
        "colab_type": "text"
      },
      "source": [
        "# SMOTE with Random Undersampling of the Majority Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPDDZpdkaHsR",
        "colab_type": "text"
      },
      "source": [
        "Previously, I ran a logistic regression and Naive Bayes model for my baseline. Following that, I ran both logistic regression and Naive Bayes using over-sampling (SMOTE) where both toxic and non-toxic values have the same count. During this run, I will be including an random undersampling of the majority class (non-toxic) after applying SMOTE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLLxFlORXg0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load files for use in the future \n",
        "# X_resample = scipy.sparse.load_npz(dst + 'X_resample.pkl.npz')\n",
        "# y_resample = np.load(dst + 'y_resample.npy')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdMDlFKLkDDC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# oversample = SMOTE() with undersampling\n",
        "over = SMOTE(sampling_strategy=0.2)\n",
        "under = RandomUnderSampler(sampling_strategy=0.5)\n",
        "steps = [('o', over), ('u', under)]\n",
        "pipeline = Pipeline(steps=steps)\n",
        "# transform the dataset\n",
        "X_resample, y_resample = pipeline.fit_resample(X, y)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AwQKYZDkXVS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ef3c9eb-d7c4-4734-f174-c126d40a9d2c"
      },
      "source": [
        "# summarize the new class distribution\n",
        "counter = Counter(y_resample)\n",
        "print(counter)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({0: 664216, 1: 332108})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTY8moUZaEuY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create x and y split for train and test sets \n",
        "\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X_resample, y_resample, stratify=y_resample)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBZg1DlZBc3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Create file for use in the future \n",
        "# scipy.sparse.save_npz(dst + '/X_resample.pkl', X_resample)\n",
        "# np.save(dst + '/y_resample.npy', y_resample)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldG6qRMV2PvO",
        "colab_type": "text"
      },
      "source": [
        "# Logistic Regression - Post SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIvRpZz161x_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "85375f66-0e3a-4ccb-e26e-4369ba564678"
      },
      "source": [
        "# Construct the LogisticRegression model\n",
        "clf = LogisticRegression()\n",
        "\n",
        "# Fit the model on the trainng data.\n",
        "clf.fit(Xtrain, ytrain)\n",
        "\n",
        "# Print the accuracy from the testing data.\n",
        "y_predict_test = clf.predict(Xtest)\n",
        "print(\"\\n\")\n",
        "print(\"[Test] Accuracy score (y_predict_test, ytest):\",accuracy_score(y_predict_test, ytest))\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"[Test] Accuracy score: (ytest, y_predict_test)\",accuracy_score(ytest, y_predict_test))\n",
        "\n",
        "y_predict_training = clf.predict(Xtrain)\n",
        "print(\"\\n\")\n",
        "print(\"[Training] Accuracy score: (ytrain, y_predict_training)\",accuracy_score(ytrain, y_predict_training))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[Test] Accuracy score (y_predict_test, ytest): 0.8755224204174545\n",
            "\n",
            "\n",
            "[Test] Accuracy score: (ytest, y_predict_test) 0.8755224204174545\n",
            "\n",
            "\n",
            "[Training] Accuracy score: (ytrain, y_predict_training) 0.8811337142000661\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNdROyxqafLy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "ce027419-79b3-4582-8699-98216e7d146f"
      },
      "source": [
        "# more comprehensive performance analysis\n",
        "\n",
        "target_names = ['Non-Toxic', 'Toxic']\n",
        "\n",
        "print(\"[Training Classification Report]\")\n",
        "print(classification_report(ytrain, y_predict_training, target_names=target_names))\n",
        "\n",
        "print(\"[Test Classification Report]\")\n",
        "print(classification_report(ytest, y_predict_test, target_names=target_names))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Training Classification Report]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Toxic       0.88      0.95      0.91    498162\n",
            "       Toxic       0.88      0.75      0.81    249081\n",
            "\n",
            "    accuracy                           0.88    747243\n",
            "   macro avg       0.88      0.85      0.86    747243\n",
            "weighted avg       0.88      0.88      0.88    747243\n",
            "\n",
            "[Test Classification Report]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Toxic       0.88      0.94      0.91    166054\n",
            "       Toxic       0.87      0.74      0.80     83027\n",
            "\n",
            "    accuracy                           0.88    249081\n",
            "   macro avg       0.87      0.84      0.85    249081\n",
            "weighted avg       0.88      0.88      0.87    249081\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqxZvpqnt51Y",
        "colab_type": "text"
      },
      "source": [
        "During the baseline run, the train dataset for non-toxic classification fared very well with precision and recall at 96% and 99% respectively. Train dataset for toxic classification fared poorly with precision and recall at 76% and 49% respectively. The test set had similar numbers.\n",
        "\n",
        "When applying SMOTE, the toxic classification, for both train and test, drastically increase to 91% and 95% for precision and recall respectively. Average precision and average recall is 93%.\n",
        "\n",
        "For SMOTE with under-sampling, we can see our results are worse for both non-toxic and toxic with similar results for train and test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Thn8zNmGFetR",
        "colab_type": "text"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdLLx4ujGEPb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27716c7f-1bf6-428d-9c45-c8c8c4f4f5c3"
      },
      "source": [
        "# multinomial naive bayes classifier\n",
        "nBayes = MultinomialNB()\n",
        "\n",
        "# same X and y used for logistic regression\n",
        "clf_nBayes = nBayes.fit(Xtrain, ytrain)\n",
        "\n",
        "accuracy_train = nBayes.score(Xtrain,ytrain)\n",
        "accuracy_test = nBayes.score(Xtest,ytest)\n",
        "\n",
        "print('The training accuracy is %f and the test accuracy is %f' %(accuracy_train, accuracy_test))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The training accuracy is 0.836772 and the test accuracy is 0.816827\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KGAR8atI2T3",
        "colab_type": "text"
      },
      "source": [
        "The gap between training and test accuracy does not imply overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ewj5faJB-pcq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "3604f648-5581-4ed6-90b8-5f5774f32ebb"
      },
      "source": [
        "\n",
        "# Print the accuracy from the testing data.\n",
        "y_predict_test = clf_nBayes.predict(Xtest)\n",
        "print(\"\\n\")\n",
        "print(\"[Test] Accuracy score (y_predict_test, ytest):\",accuracy_score(y_predict_test, ytest))\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"[Test] Accuracy score: (ytest, y_predict_test)\",accuracy_score(ytest, y_predict_test))\n",
        "\n",
        "y_predict_training = clf_nBayes.predict(Xtrain)\n",
        "print(\"\\n\")\n",
        "print(\"[Training] Accuracy score: (ytrain, y_predict_training)\",accuracy_score(ytrain, y_predict_training))\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "[Test] Accuracy score (y_predict_test, ytest): 0.8168266547829822\n",
            "\n",
            "\n",
            "[Test] Accuracy score: (ytest, y_predict_test) 0.8168266547829822\n",
            "\n",
            "\n",
            "[Training] Accuracy score: (ytrain, y_predict_training) 0.8367719737755991\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CadboD-f_RVs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "080a7e40-a8ab-4b6d-90b0-f25073a4472b"
      },
      "source": [
        "# more comprehensive performance analysis for NB\n",
        "\n",
        "target_names = ['Non-Toxic', 'Toxic']\n",
        "\n",
        "print(\"[Training Classification Report]\")\n",
        "print(classification_report(ytrain, y_predict_training, target_names=target_names))\n",
        "\n",
        "print(\"[Test Classification Report]\")\n",
        "print(classification_report(ytest, y_predict_test, target_names=target_names))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Training Classification Report]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Toxic       0.86      0.91      0.88    498162\n",
            "       Toxic       0.79      0.70      0.74    249081\n",
            "\n",
            "    accuracy                           0.84    747243\n",
            "   macro avg       0.82      0.80      0.81    747243\n",
            "weighted avg       0.83      0.84      0.83    747243\n",
            "\n",
            "[Test Classification Report]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   Non-Toxic       0.85      0.89      0.87    166054\n",
            "       Toxic       0.75      0.68      0.71     83027\n",
            "\n",
            "    accuracy                           0.82    249081\n",
            "   macro avg       0.80      0.78      0.79    249081\n",
            "weighted avg       0.81      0.82      0.81    249081\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g2Ruc9OcATq4"
      },
      "source": [
        "In a similar manner to the logistic regression results, the non-toxic and toxic classification for both the train and test set is better than baseline but worse than SMOTE. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPbX6lOhsDe0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate roc curve\n",
        "fpr, tpr, thresholds = roc_curve(ytrain, y_predict_training)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhuLwITDxOnm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a19c3c5-1734-459c-ab9b-8e3cc42f044b"
      },
      "source": [
        "# calculate AUC\n",
        "auc = roc_auc_score(ytrain, y_predict_training)\n",
        "print('AUC: %.3f' % auc)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC: 0.802\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ-gjBr-rddc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "70e1e09d-3384-448e-acd6-5068a7f9bac4"
      },
      "source": [
        "# plot the roc curve for the model\n",
        "plt.plot(fpr, tpr, linestyle='--')\n",
        "\n",
        "# axis labels\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "# show the legend\n",
        "plt.legend()\n",
        "# show the plot\n",
        "plt.show()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No handles with labels found to put in legend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJ38hW3pvheQ",
        "colab_type": "text"
      },
      "source": [
        "A good measure of separability implying an excellent model is an AUC near 1. When AUC is 0.5, it means model has no class separation capacity whatsoever. Given an AUC of 0.80, it means there is 80% chance that model will be able to distinguish between positive class (toxic) and negative class (non-toxic). The baseline and SMOTE AUC was 0.81.\n"
      ]
    }
  ]
}